{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Multi-Agent System MAS using GNN + RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Synthetic Data\n",
    "- <b>water_level</b>: The current water level at each node at each timestep. It is updated based on inflows (both natural and from neighboring nodes) and outflows (controlled by the valve).\n",
    "- <b>inflow_rate</b>: The natural inflow rate into the node, modulated by a seasonal/cyclic pattern.\n",
    "- <b>outflow_rate</b>: The outflow rate is a function of the valve position and the node's current water level.\n",
    "- <b>valve_position</b>: The valve position for each node, controlling how much water flows out. It can be controlled by your policy network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>node</th>\n",
       "      <th>water_level</th>\n",
       "      <th>inflow_rate</th>\n",
       "      <th>outflow_rate</th>\n",
       "      <th>valve_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.658367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.508283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.723192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.560286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step  node  water_level  inflow_rate  outflow_rate  valve_position\n",
       "0          0     0     1.658367          0.0           0.0        0.677564\n",
       "1          0     1     0.798074          0.0           0.0        0.016588\n",
       "2          0     2     0.508283          0.0           0.0        0.512093\n",
       "3          0     3     1.723192          0.0           0.0        0.226496\n",
       "4          0     4     1.560286          0.0           0.0        0.645173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge_index</th>\n",
       "      <th>source_node</th>\n",
       "      <th>target_node</th>\n",
       "      <th>flow_capacity</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1.749080</td>\n",
       "      <td>4.137788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>2.901429</td>\n",
       "      <td>1.870762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "      <td>2.463988</td>\n",
       "      <td>0.939525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>2.197317</td>\n",
       "      <td>3.579049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1.312037</td>\n",
       "      <td>2.480686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edge_index  source_node  target_node  flow_capacity  distance\n",
       "0           0            4           23       1.749080  4.137788\n",
       "1           1            5           52       2.901429  1.870762\n",
       "2           2            5           79       2.463988  0.939525\n",
       "3           3            5           46       2.197317  3.579049\n",
       "4           4            6           13       1.312037  2.480686"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_nodes = 100\n",
    "num_edges = 35\n",
    "time_steps = 100\n",
    "\n",
    "seasonal_cycle_length = 1440  # Cyclic pattern\n",
    "np.random.seed(42)\n",
    "\n",
    "G = nx.gnm_random_graph(num_nodes, num_edges)\n",
    "edge_list = np.array(G.edges())\n",
    "num_edges = edge_list.shape[0]\n",
    "\n",
    "# Flow Cap and Distances between nodes\n",
    "flow_capacities = np.random.uniform(low=1.0, high=3.0, size=(num_edges,))\n",
    "distances = np.random.uniform(low=0.5, high=5.0, size=(num_edges,))\n",
    "\n",
    "# Simulating rainfall and evaporation with Synthetic Rainfall Cycle\n",
    "time = np.arange(time_steps)\n",
    "seasonal_pattern = np.sin(2 * np.pi * time / seasonal_cycle_length) * 0.2 + 0.3\n",
    "\n",
    "initial_water_levels = np.random.uniform(low=0.5, high=2.0, size=num_nodes)\n",
    "\n",
    "# Node interaction based on graph structure\n",
    "water_levels = np.zeros((time_steps, num_nodes))\n",
    "inflow_rates = np.zeros((time_steps, num_nodes))\n",
    "outflow_rates = np.zeros((time_steps, num_nodes))\n",
    "valve_positions = np.zeros((time_steps, num_nodes))\n",
    "\n",
    "# Initial time step\n",
    "water_levels[0, :] = initial_water_levels\n",
    "valve_positions[0, :] = np.random.uniform(low=0.0, high=1.0, size=num_nodes)\n",
    "\n",
    "# Inflow, outflow, and water level dynamics\n",
    "for t in range(1, time_steps):\n",
    "    inflow_rates[t, :] = seasonal_pattern[t % seasonal_cycle_length] + np.random.uniform(0.1, 0.5, size=num_nodes)\n",
    "    valve_positions[t, :] = np.random.uniform(low=0.0, high=1.0, size=num_nodes)\n",
    "    \n",
    "    # Outflow rate depends on the valve position and previous node's water level\n",
    "    outflow_rates[t, :] = valve_positions[t, :] * water_levels[t - 1, :]\n",
    "    \n",
    "    # Update water levels based on inflow and outflow\n",
    "    for node in range(num_nodes):\n",
    "        inflow_from_neighbors = 0\n",
    "        for edge_idx, (src, tgt) in enumerate(edge_list):\n",
    "            if tgt == node:\n",
    "                inflow_from_neighbors += flow_capacities[edge_idx] * outflow_rates[t - 1, src] / distances[edge_idx]\n",
    "        \n",
    "        water_levels[t, node] = water_levels[t - 1, node] + inflow_rates[t, node] + inflow_from_neighbors - outflow_rates[t, node]\n",
    "        water_levels[t, node] = np.clip(water_levels[t, node], 0, 2.0)\n",
    "\n",
    "data = {\n",
    "    'time_step': np.repeat(np.arange(time_steps), num_nodes),\n",
    "    'node': np.tile(np.arange(num_nodes), time_steps),\n",
    "    'water_level': water_levels.flatten(),\n",
    "    'inflow_rate': inflow_rates.flatten(),\n",
    "    'outflow_rate': outflow_rates.flatten(),\n",
    "    'valve_position': valve_positions.flatten(),\n",
    "}\n",
    "df_nodes = pd.DataFrame(data)\n",
    "\n",
    "df_edges = pd.DataFrame({\n",
    "    'edge_index': np.arange(num_edges),\n",
    "    'source_node': edge_list[:, 0],\n",
    "    'target_node': edge_list[:, 1],\n",
    "    'flow_capacity': flow_capacities,\n",
    "    'distance': distances,\n",
    "})\n",
    "\n",
    "display(df_nodes.head())\n",
    "display(df_edges.head())\n",
    "\n",
    "flow_capacities = torch.tensor(flow_capacities, dtype=torch.float)\n",
    "distances = torch.tensor(distances, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple GNN Architecture\n",
    "$$\n",
    "h_v^{(k+1)} = \\sigma \\left( \\sum_{u \\in \\mathcal{N}(v)} \\frac{1}{\\sqrt{d_u d_v}} W^{(k)} h_u^{(k)} \\right)\n",
    "$$\n",
    "\n",
    "where $ h_v^{(k)} $ represents the node features at layer $ k $, and $ W^{(k)} $ is the weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE GNN Simple Arch\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.3)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.3)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reinforcement Learning (Policy Network)\n",
    "The policy network in the RL model maps the state to an action:\n",
    "\n",
    "$$\n",
    "\\text{Action} = \\text{PolicyNetwork}(State)\n",
    "$$\n",
    "\n",
    "Optimization Methods\n",
    "- Switching Optimizer\n",
    "- Hierarchical RL\n",
    "- Aggergator Method (Could Try but from theory calculation it's not good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE Simple DRL | Switch Optimizing (Local and Global)\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.tanh(self.fc3(x))\n",
    "\n",
    "# Local control (Per-Node)\n",
    "def local_control(node_representations, policy_network):\n",
    "    actions = policy_network(node_representations)\n",
    "    return actions\n",
    "\n",
    "# Global control (coordination all nodes)\n",
    "def global_control(node_representations, policy_network):\n",
    "    graph_representation = torch.mean(node_representations, dim=0)\n",
    "    global_action = policy_network(graph_representation)\n",
    "    actions = global_action.expand(node_representations.shape[0], -1)\n",
    "    return actions\n",
    "\n",
    "# Switching mechanism for local and global control\n",
    "def hybrid_control(node_representations, policy_network, global_threshold, current_water_levels):\n",
    "    max_water_level = torch.max(current_water_levels)\n",
    "    \n",
    "    if max_water_level > global_threshold:\n",
    "        print(\"Switching to Global Control!\")\n",
    "        actions = global_control(node_representations, policy_network)\n",
    "    else:\n",
    "        print(\"Using Local Control.\")\n",
    "        actions = local_control(node_representations, policy_network)    \n",
    "    return actions\n",
    "\n",
    "def environment_step(state, action, edge_index, flow_capacities):\n",
    "    inflow_rate = state[:, 1]\n",
    "    \n",
    "    # print(f\"Inflow Rate {inflow_rate.shape}\")    \n",
    "    # print(f\"State shape: {state.shape}\")\n",
    "    # print(f\"Initial action shape: {action.shape}\")  \n",
    "    \n",
    "    if action.dim() == 2 and action.shape[0] < state.shape[0]:\n",
    "        action = action.repeat(state.shape[0] // action.shape[0], 1)\n",
    "    # print(f\"Action shape after repeat: {action.shape}\")  \n",
    "    \n",
    "    # outflow_rate = state[:, 2] + action.squeeze()\n",
    "    outflow_rate = state[:, 2] + action[:, 0]\n",
    "    # print(f\"State Shape {state[:, 2].shape}\", f\"Action Shape {action.shape}\")\n",
    "    \n",
    "    inflow_rate_new = inflow_rate.clone()\n",
    "    for edge_idx, (src, tgt) in enumerate(edge_list):\n",
    "        # print(f\"Inflow Rate: {inflow_rate[tgt]}\")\n",
    "        # print(f\"Outflow Rate: {outflow_rate[src]}\")\n",
    "        # print(f\"Flow Cap {flow_capacities[edge_idx]}\", f\"Distance {distances[edge_idx]}\")\n",
    "        inflow_rate_new[tgt] += flow_capacities[edge_idx] * outflow_rate[src] / distances[edge_idx]\n",
    "    \n",
    "    outflow_rate = torch.clamp(outflow_rate, 0, 1)\n",
    "    new_water_level = state[:, 0] + inflow_rate_new - outflow_rate\n",
    "    new_water_level = torch.clamp(new_water_level, 0, 2)\n",
    "    \n",
    "    new_state = torch.stack((new_water_level, state[:, 1], outflow_rate, state[:, 3]), dim=1)\n",
    "    overflow_pen = overflow_penalty(new_state)\n",
    "    stability = stability_reward(new_state)\n",
    "    reward = overflow_pen + stability\n",
    "    \n",
    "    return new_state, reward\n",
    "\n",
    "def overflow_penalty(state):\n",
    "    penalty = torch.clamp(state[:, 0] - 1.5, min=0)\n",
    "    return -torch.sum(penalty) * 10  # Higher penalty for overflow\n",
    "\n",
    "def stability_reward(state):\n",
    "    ideal_level = 1.0\n",
    "    return -torch.mean((state[:, 0] - ideal_level) ** 2)  # Minimize deviation from the ideal level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Steps (Might be bottlenecked by computational resources)\n",
    "- MARL\n",
    "- Advanced Reward System\n",
    "- Testing different learning strats (PPO vs Q-Learning vs A2C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE Simple but effective way to add X features (Could improve in later phases)\n",
    "gnn_in_chan = 4  # aka. Num Input Feat (e.g, water_level, inflow_rate, outflow_rate, valve_position)\n",
    "node_features = np.zeros((time_steps, num_nodes, gnn_in_chan))\n",
    "for t in range(time_steps):\n",
    "    for n in range(num_nodes):\n",
    "        node_features[t, n, 0] = df_nodes.loc[(df_nodes['time_step'] == t) & (df_nodes['node'] == n), 'water_level'].values[0]\n",
    "        node_features[t, n, 1] = df_nodes.loc[(df_nodes['time_step'] == t) & (df_nodes['node'] == n), 'inflow_rate'].values[0]\n",
    "        node_features[t, n, 2] = df_nodes.loc[(df_nodes['time_step'] == t) & (df_nodes['node'] == n), 'outflow_rate'].values[0]\n",
    "        node_features[t, n, 3] = df_nodes.loc[(df_nodes['time_step'] == t) & (df_nodes['node'] == n), 'valve_position'].values[0]\n",
    "node_features_tensor = torch.tensor(node_features, dtype=torch.float)\n",
    "# NOTE Will need LSTM for multi-step to deal with sequencial data: node_features_tensor.to(device)\n",
    "# single_immediate_features = node_features[0] # NOTE for immediate condition (Snapshot)\n",
    "# single_immediate_features_tensor = torch.tensor(single_immediate_features, dtype=torch.float).to(device)\n",
    "# print(f\"Node Features: {node_features.shape}\")\n",
    "# print(f\"Single Node Features: {single_immediate_features.shape}\")\n",
    "\n",
    "# water_data = from_networkx(G)\n",
    "# water_data.x = single_immediate_features_tensor\n",
    "# water_data.edge_index = water_data.edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_data = from_networkx(G)\n",
    "\n",
    "train_steps = int(0.7 * time_steps)\n",
    "val_steps = int(0.15 * time_steps)\n",
    "test_steps = time_steps - train_steps - val_steps\n",
    "\n",
    "train_node_features = node_features_tensor[:train_steps, :, :].reshape(-1, gnn_in_chan).to(device)\n",
    "val_node_features = node_features_tensor[train_steps:train_steps+val_steps, :, :].reshape(-1, gnn_in_chan).to(device)\n",
    "test_node_features = node_features_tensor[train_steps+val_steps:, :, :].reshape(-1, gnn_in_chan).to(device)\n",
    "\n",
    "train_edge_index = water_data.edge_index[:, :train_steps]\n",
    "val_edge_index = water_data.edge_index[:, train_steps:train_steps+val_steps]\n",
    "test_edge_index = water_data.edge_index[:, train_steps+val_steps:]  \n",
    "\n",
    "train_data = Data(x=train_node_features, edge_index=train_edge_index.to(device))\n",
    "val_data = Data(x=val_node_features, edge_index=val_edge_index.to(device))\n",
    "test_data = Data(x=test_node_features, edge_index=test_edge_index.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 0: Train Loss: 0.9912256002426147, Val Loss: 0.9409996867179871\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 1: Train Loss: 0.9449146389961243, Val Loss: 0.8389946222305298\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 2: Train Loss: 0.8423213958740234, Val Loss: 0.65670245885849\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 3: Train Loss: 0.6787669658660889, Val Loss: 0.48555704951286316\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 4: Train Loss: 0.49235671758651733, Val Loss: 0.31304121017456055\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 5: Train Loss: 1.396718144416809, Val Loss: 0.31006038188934326\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 6: Train Loss: 0.3130315840244293, Val Loss: 0.2983452379703522\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 7: Train Loss: 0.29199206829071045, Val Loss: 0.2716655731201172\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 8: Train Loss: 0.26894474029541016, Val Loss: 0.23146627843379974\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 9: Train Loss: 0.25993192195892334, Val Loss: 0.2376331090927124\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 10: Train Loss: 0.24650070071220398, Val Loss: 0.24439497292041779\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 11: Train Loss: 0.2401518076658249, Val Loss: 0.2363029420375824\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 12: Train Loss: 0.23450936377048492, Val Loss: 0.2252955436706543\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 13: Train Loss: 0.2223944365978241, Val Loss: 0.2048887461423874\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 14: Train Loss: 0.21273311972618103, Val Loss: 0.19188733398914337\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 15: Train Loss: 0.19217823445796967, Val Loss: 0.17208054661750793\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 16: Train Loss: 3.215904712677002, Val Loss: 0.19627368450164795\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 17: Train Loss: 0.20232446491718292, Val Loss: 1.3310493230819702\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 18: Train Loss: 0.22813846170902252, Val Loss: 0.25306323170661926\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 19: Train Loss: 0.24970535933971405, Val Loss: 0.2744819223880768\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 20: Train Loss: 0.27025488018989563, Val Loss: 0.2821936011314392\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 21: Train Loss: 0.2844264805316925, Val Loss: 0.2966170310974121\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 22: Train Loss: 0.2956821918487549, Val Loss: 0.29756441712379456\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 23: Train Loss: 0.2980584502220154, Val Loss: 0.2958471179008484\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 24: Train Loss: 0.2969723343849182, Val Loss: 0.2924453914165497\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 25: Train Loss: 0.2923412024974823, Val Loss: 0.2868378758430481\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 26: Train Loss: 0.28383177518844604, Val Loss: 0.2732846140861511\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 27: Train Loss: 0.27424055337905884, Val Loss: 0.2591525912284851\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 28: Train Loss: 0.6017516851425171, Val Loss: 0.26298147439956665\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 29: Train Loss: 0.2580585479736328, Val Loss: 0.26440849900245667\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 30: Train Loss: 1.1847896575927734, Val Loss: 0.2696176767349243\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 31: Train Loss: 1.0743749141693115, Val Loss: 0.29886218905448914\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 32: Train Loss: 0.2903313636779785, Val Loss: 0.31315523386001587\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 33: Train Loss: 0.3087870478630066, Val Loss: 0.3264441192150116\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 34: Train Loss: 0.3200036287307739, Val Loss: 0.33808284997940063\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 35: Train Loss: 2.4930615425109863, Val Loss: 0.3942696750164032\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 36: Train Loss: 0.3818150758743286, Val Loss: 0.4261479079723358\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 37: Train Loss: 0.42575812339782715, Val Loss: 0.471717894077301\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 38: Train Loss: 0.4645160138607025, Val Loss: 0.5054043531417847\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 39: Train Loss: 0.5009956359863281, Val Loss: 0.5434033870697021\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 40: Train Loss: 0.5234950184822083, Val Loss: 0.5692756175994873\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 41: Train Loss: 0.5482214689254761, Val Loss: 0.5791229009628296\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 42: Train Loss: 0.5704304575920105, Val Loss: 0.6028713583946228\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 43: Train Loss: 0.5871985554695129, Val Loss: 0.6008328199386597\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 44: Train Loss: 0.5959800481796265, Val Loss: 0.6121190786361694\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 45: Train Loss: 0.6004939675331116, Val Loss: 0.616028368473053\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 46: Train Loss: 0.6020376086235046, Val Loss: 0.6139352321624756\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 47: Train Loss: 0.6029179096221924, Val Loss: 0.60822993516922\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 48: Train Loss: 0.5991431474685669, Val Loss: 0.5951910018920898\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 49: Train Loss: 0.5965108275413513, Val Loss: 0.5949416160583496\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 50: Train Loss: 0.5843707323074341, Val Loss: 0.5791149139404297\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 51: Train Loss: 0.573696494102478, Val Loss: 0.570917010307312\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 52: Train Loss: 0.5569295883178711, Val Loss: 0.5541849136352539\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 53: Train Loss: 0.5439226627349854, Val Loss: 0.5250917673110962\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 54: Train Loss: 0.528211772441864, Val Loss: 0.5181013345718384\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 55: Train Loss: 0.5094812512397766, Val Loss: 0.49959415197372437\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 56: Train Loss: 0.48567259311676025, Val Loss: 0.46975642442703247\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 57: Train Loss: 0.4591678977012634, Val Loss: 0.44267627596855164\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 58: Train Loss: 0.4351964592933655, Val Loss: 0.41733992099761963\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 59: Train Loss: 0.4101790487766266, Val Loss: 0.3946940004825592\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 60: Train Loss: 0.3820311725139618, Val Loss: 0.365036278963089\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 61: Train Loss: 0.35554370284080505, Val Loss: 0.33497968316078186\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 62: Train Loss: 0.32707643508911133, Val Loss: 0.3012118637561798\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 63: Train Loss: 0.29813382029533386, Val Loss: 0.27327069640159607\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 64: Train Loss: 0.38668397068977356, Val Loss: 0.26557275652885437\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 65: Train Loss: 0.2606315314769745, Val Loss: 0.2546231746673584\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 66: Train Loss: 0.25198251008987427, Val Loss: 0.24795503914356232\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 67: Train Loss: 0.24199695885181427, Val Loss: 0.232448011636734\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 68: Train Loss: 0.2293880134820938, Val Loss: 0.22366133332252502\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 69: Train Loss: 0.21516960859298706, Val Loss: 0.20684759318828583\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 70: Train Loss: 0.20436035096645355, Val Loss: 0.1923181563615799\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 71: Train Loss: 0.18915854394435883, Val Loss: 0.1767074018716812\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 72: Train Loss: 0.17518003284931183, Val Loss: 0.15562094748020172\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 73: Train Loss: 0.36920231580734253, Val Loss: 0.172427237033844\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 74: Train Loss: 1.068318486213684, Val Loss: 0.20932011306285858\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 75: Train Loss: 0.20839647948741913, Val Loss: 0.2501102387905121\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 76: Train Loss: 0.24296367168426514, Val Loss: 0.2704700827598572\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 77: Train Loss: 0.2738228142261505, Val Loss: 0.2990887761116028\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 78: Train Loss: 0.30036768317222595, Val Loss: 0.3190179467201233\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 79: Train Loss: 0.3241463005542755, Val Loss: 0.3463380038738251\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 80: Train Loss: 0.34343478083610535, Val Loss: 0.3638574182987213\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 81: Train Loss: 0.360015332698822, Val Loss: 0.3716579079627991\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 82: Train Loss: 0.3743288815021515, Val Loss: 0.3817111849784851\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 83: Train Loss: 0.38335466384887695, Val Loss: 0.3930128514766693\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 84: Train Loss: 0.39041754603385925, Val Loss: 0.40107396245002747\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 85: Train Loss: 0.39611533284187317, Val Loss: 0.3974798917770386\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 86: Train Loss: 0.3974399268627167, Val Loss: 0.3980647027492523\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 87: Train Loss: 0.3967406451702118, Val Loss: 0.38605406880378723\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 88: Train Loss: 0.3929455578327179, Val Loss: 0.3882436156272888\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 89: Train Loss: 0.3902069628238678, Val Loss: 0.3867340087890625\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 90: Train Loss: 0.3829911947250366, Val Loss: 0.3768848478794098\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 91: Train Loss: 0.376422256231308, Val Loss: 0.367170125246048\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 92: Train Loss: 0.36599573493003845, Val Loss: 0.3555704653263092\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 93: Train Loss: 0.3550454080104828, Val Loss: 0.34086355566978455\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 94: Train Loss: 0.34885936975479126, Val Loss: 0.33318373560905457\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 95: Train Loss: 0.33102768659591675, Val Loss: 0.30843791365623474\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 96: Train Loss: 0.32207420468330383, Val Loss: 0.3010247051715851\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 97: Train Loss: 0.30673539638519287, Val Loss: 0.2858057916164398\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 98: Train Loss: 0.291546106338501, Val Loss: 0.2803250551223755\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 99: Train Loss: 0.27580979466438293, Val Loss: 0.2574891448020935\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 100: Train Loss: 0.2607540190219879, Val Loss: 0.23654939234256744\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 101: Train Loss: 0.24505741894245148, Val Loss: 0.22319839894771576\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 102: Train Loss: 0.22895964980125427, Val Loss: 0.2072332799434662\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 103: Train Loss: 0.21483993530273438, Val Loss: 0.18868480622768402\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 104: Train Loss: 0.19968101382255554, Val Loss: 0.18036706745624542\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 105: Train Loss: 0.1855226755142212, Val Loss: 0.16269010305404663\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 106: Train Loss: 0.16910935938358307, Val Loss: 0.14900484681129456\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 107: Train Loss: 0.1519172340631485, Val Loss: 0.13267797231674194\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 108: Train Loss: 0.14078550040721893, Val Loss: 0.1237609013915062\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 109: Train Loss: 0.49519142508506775, Val Loss: 0.13341566920280457\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 110: Train Loss: 1.3384531736373901, Val Loss: 0.15187473595142365\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 111: Train Loss: 0.15993733704090118, Val Loss: 0.1786123812198639\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 112: Train Loss: 0.1794404238462448, Val Loss: 0.1889539361000061\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 113: Train Loss: 0.20102332532405853, Val Loss: 0.212595596909523\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 114: Train Loss: 0.2141917645931244, Val Loss: 0.22419895231723785\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 115: Train Loss: 0.2302219420671463, Val Loss: 0.23622122406959534\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 116: Train Loss: 0.23990000784397125, Val Loss: 0.24121324717998505\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 117: Train Loss: 0.2530834972858429, Val Loss: 0.253913551568985\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 118: Train Loss: 0.25654172897338867, Val Loss: 0.2598555088043213\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 119: Train Loss: 0.26185253262519836, Val Loss: 0.2693201005458832\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 120: Train Loss: 0.27030348777770996, Val Loss: 0.27240505814552307\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 121: Train Loss: 0.2667384445667267, Val Loss: 0.2630353569984436\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 122: Train Loss: 0.2715761661529541, Val Loss: 0.2648354172706604\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 123: Train Loss: 0.2703253924846649, Val Loss: 0.2685263156890869\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 124: Train Loss: 0.27042677998542786, Val Loss: 0.2658492922782898\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 125: Train Loss: 0.26687702536582947, Val Loss: 0.25697654485702515\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 126: Train Loss: 0.26194241642951965, Val Loss: 0.2431567758321762\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 127: Train Loss: 0.2577747106552124, Val Loss: 0.24054273962974548\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 128: Train Loss: 0.25372442603111267, Val Loss: 0.24241487681865692\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 129: Train Loss: 0.24288828670978546, Val Loss: 0.23500306904315948\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 130: Train Loss: 0.23544108867645264, Val Loss: 0.22047358751296997\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 131: Train Loss: 0.23103393614292145, Val Loss: 0.21231234073638916\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 132: Train Loss: 0.21921145915985107, Val Loss: 0.19926132261753082\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 133: Train Loss: 0.21155424416065216, Val Loss: 0.19467638432979584\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 134: Train Loss: 0.20018982887268066, Val Loss: 0.18298600614070892\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 135: Train Loss: 0.18885622918605804, Val Loss: 0.16883882880210876\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 136: Train Loss: 0.17848460376262665, Val Loss: 0.16062761843204498\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 137: Train Loss: 0.16535012423992157, Val Loss: 0.1495320051908493\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 138: Train Loss: 0.21315079927444458, Val Loss: 0.14800558984279633\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 139: Train Loss: 0.15523071587085724, Val Loss: 0.1472351998090744\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 140: Train Loss: 1.0813946723937988, Val Loss: 0.16533003747463226\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 141: Train Loss: 0.1669531613588333, Val Loss: 0.17567947506904602\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 142: Train Loss: 0.1822296679019928, Val Loss: 0.18786616623401642\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 143: Train Loss: 0.18990746140480042, Val Loss: 0.1878032684326172\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 144: Train Loss: 0.1975497156381607, Val Loss: 0.19720971584320068\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 145: Train Loss: 0.20389299094676971, Val Loss: 0.19928719103336334\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 146: Train Loss: 0.2099468857049942, Val Loss: 0.2018691450357437\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 147: Train Loss: 0.21379077434539795, Val Loss: 0.21650995314121246\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 148: Train Loss: 0.21496634185314178, Val Loss: 0.20671872794628143\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 149: Train Loss: 0.2168114334344864, Val Loss: 0.21270743012428284\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 150: Train Loss: 0.21537218987941742, Val Loss: 0.2075149267911911\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 151: Train Loss: 0.21457873284816742, Val Loss: 0.20822200179100037\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 152: Train Loss: 0.212154820561409, Val Loss: 0.2010519802570343\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 153: Train Loss: 0.21024270355701447, Val Loss: 0.19556953012943268\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 154: Train Loss: 0.20633399486541748, Val Loss: 0.1921139359474182\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 155: Train Loss: 0.19904962182044983, Val Loss: 0.18650101125240326\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 156: Train Loss: 0.19649262726306915, Val Loss: 0.18623463809490204\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 157: Train Loss: 0.1907823234796524, Val Loss: 0.18007692694664001\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 158: Train Loss: 0.18477116525173187, Val Loss: 0.16970351338386536\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 159: Train Loss: 0.18077239394187927, Val Loss: 0.16867198050022125\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 160: Train Loss: 0.17602211236953735, Val Loss: 0.16155622899532318\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 161: Train Loss: 0.1670360565185547, Val Loss: 0.15753903985023499\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 162: Train Loss: 0.2944333553314209, Val Loss: 0.1622835099697113\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 163: Train Loss: 0.16936352849006653, Val Loss: 0.17021296918392181\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 164: Train Loss: 0.17940397560596466, Val Loss: 0.17645485699176788\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 165: Train Loss: 0.1829300969839096, Val Loss: 0.1802692711353302\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 166: Train Loss: 0.18827004730701447, Val Loss: 0.18374472856521606\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 167: Train Loss: 0.1898089349269867, Val Loss: 0.18506410717964172\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 168: Train Loss: 0.19353260099887848, Val Loss: 0.18008695542812347\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 169: Train Loss: 0.19409623742103577, Val Loss: 0.17616255581378937\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 170: Train Loss: 0.19034068286418915, Val Loss: 0.17540742456912994\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 171: Train Loss: 0.18622258305549622, Val Loss: 0.17416225373744965\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 172: Train Loss: 0.1810295432806015, Val Loss: 0.16927523910999298\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 173: Train Loss: 0.17540958523750305, Val Loss: 0.15595878660678864\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 174: Train Loss: 0.1671190708875656, Val Loss: 0.1543220430612564\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 175: Train Loss: 0.16036945581436157, Val Loss: 0.14119987189769745\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 176: Train Loss: 0.1530715674161911, Val Loss: 0.13787682354450226\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 177: Train Loss: 0.14476042985916138, Val Loss: 0.12813884019851685\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 178: Train Loss: 0.13561098277568817, Val Loss: 0.11780810356140137\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 179: Train Loss: 0.129580557346344, Val Loss: 0.11373212933540344\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 180: Train Loss: 0.11963560432195663, Val Loss: 0.10958068817853928\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 181: Train Loss: 0.10977014154195786, Val Loss: 0.09658398479223251\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 182: Train Loss: 0.10418844223022461, Val Loss: 0.08751662075519562\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 183: Train Loss: 0.17258767783641815, Val Loss: 0.09870253503322601\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 184: Train Loss: 0.10385982692241669, Val Loss: 0.10787957906723022\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 185: Train Loss: 0.11261353641748428, Val Loss: 0.10882081836462021\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 186: Train Loss: 0.11776722967624664, Val Loss: 0.1110377386212349\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 187: Train Loss: 0.8856428265571594, Val Loss: 0.13392356038093567\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 188: Train Loss: 0.13963425159454346, Val Loss: 0.15334682166576385\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 189: Train Loss: 0.1589425504207611, Val Loss: 0.16083139181137085\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 190: Train Loss: 0.17613950371742249, Val Loss: 0.18415950238704681\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 191: Train Loss: 0.18901628255844116, Val Loss: 0.19423329830169678\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 192: Train Loss: 0.20183886587619781, Val Loss: 0.20910333096981049\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 193: Train Loss: 0.2120407372713089, Val Loss: 0.2132950872182846\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 194: Train Loss: 0.22184117138385773, Val Loss: 0.2248269021511078\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 195: Train Loss: 0.22936755418777466, Val Loss: 0.22176992893218994\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 196: Train Loss: 0.2362612634897232, Val Loss: 0.22783704102039337\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 197: Train Loss: 0.23740680515766144, Val Loss: 0.22672250866889954\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 198: Train Loss: 0.2396930754184723, Val Loss: 0.23496711254119873\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 199: Train Loss: 0.24017304182052612, Val Loss: 0.233354851603508\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 200: Train Loss: 0.2425054907798767, Val Loss: 0.23204992711544037\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 201: Train Loss: 0.23984378576278687, Val Loss: 0.2321910709142685\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 202: Train Loss: 0.23840729892253876, Val Loss: 0.2256162315607071\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 203: Train Loss: 0.23509982228279114, Val Loss: 0.21958963572978973\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 204: Train Loss: 0.2337123602628708, Val Loss: 0.21732591092586517\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 205: Train Loss: 0.2281092256307602, Val Loss: 0.21734732389450073\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 206: Train Loss: 0.22577008605003357, Val Loss: 0.20782873034477234\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 207: Train Loss: 0.21728825569152832, Val Loss: 0.20535525679588318\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 208: Train Loss: 0.21545587480068207, Val Loss: 0.19835039973258972\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 209: Train Loss: 0.20726467669010162, Val Loss: 0.19407543540000916\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 210: Train Loss: 0.2042667418718338, Val Loss: 0.1846780627965927\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 211: Train Loss: 0.19800834357738495, Val Loss: 0.1784360706806183\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 212: Train Loss: 0.18951202929019928, Val Loss: 0.18104219436645508\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 213: Train Loss: 0.18551546335220337, Val Loss: 0.16710534691810608\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 214: Train Loss: 0.17825749516487122, Val Loss: 0.1591782420873642\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 215: Train Loss: 0.1718817949295044, Val Loss: 0.15680208802223206\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 216: Train Loss: 0.16424895823001862, Val Loss: 0.15050369501113892\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 217: Train Loss: 0.15819139778614044, Val Loss: 0.14478446543216705\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 218: Train Loss: 0.15164336562156677, Val Loss: 0.13896657526493073\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 219: Train Loss: 0.1472451090812683, Val Loss: 0.12608332931995392\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 220: Train Loss: 0.14053165912628174, Val Loss: 0.12797990441322327\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 221: Train Loss: 0.13406114280223846, Val Loss: 0.11853678524494171\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 222: Train Loss: 0.12795081734657288, Val Loss: 0.11213889718055725\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 223: Train Loss: 0.12257970124483109, Val Loss: 0.10966099053621292\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 224: Train Loss: 0.48678115010261536, Val Loss: 0.1176934614777565\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 225: Train Loss: 0.12337057292461395, Val Loss: 0.12568147480487823\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 226: Train Loss: 0.13108518719673157, Val Loss: 0.12807638943195343\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 227: Train Loss: 0.2310163676738739, Val Loss: 0.14125680923461914\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 228: Train Loss: 0.15150906145572662, Val Loss: 0.15239961445331573\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 229: Train Loss: 0.1636410355567932, Val Loss: 0.1641409695148468\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 230: Train Loss: 0.17761997878551483, Val Loss: 0.1780502051115036\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 231: Train Loss: 0.18541604280471802, Val Loss: 0.18978680670261383\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 232: Train Loss: 0.194919154047966, Val Loss: 0.19174925982952118\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 233: Train Loss: 0.20224344730377197, Val Loss: 0.19662413001060486\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 234: Train Loss: 0.2076597809791565, Val Loss: 0.2060682773590088\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 235: Train Loss: 0.21278752386569977, Val Loss: 0.20796361565589905\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 236: Train Loss: 0.21598224341869354, Val Loss: 0.21161401271820068\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 237: Train Loss: 0.2181277722120285, Val Loss: 0.2045394629240036\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 238: Train Loss: 0.21652434766292572, Val Loss: 0.21263964474201202\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 239: Train Loss: 0.2170841544866562, Val Loss: 0.2090630829334259\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 240: Train Loss: 0.21917246282100677, Val Loss: 0.2094651311635971\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 241: Train Loss: 0.21622659265995026, Val Loss: 0.20805516839027405\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 242: Train Loss: 0.21619655191898346, Val Loss: 0.20659086108207703\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 243: Train Loss: 0.2130451649427414, Val Loss: 0.1945715695619583\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 244: Train Loss: 0.21074078977108002, Val Loss: 0.19318965077400208\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 245: Train Loss: 0.2053924947977066, Val Loss: 0.1925228387117386\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 246: Train Loss: 0.20343899726867676, Val Loss: 0.1900371015071869\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 247: Train Loss: 0.19845302402973175, Val Loss: 0.1828455775976181\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 248: Train Loss: 0.19428867101669312, Val Loss: 0.18177734315395355\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 249: Train Loss: 0.18881259858608246, Val Loss: 0.17528149485588074\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 250: Train Loss: 0.1826968491077423, Val Loss: 0.16691192984580994\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 251: Train Loss: 0.17708931863307953, Val Loss: 0.16334441304206848\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 252: Train Loss: 0.17238523066043854, Val Loss: 0.1603286862373352\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 253: Train Loss: 0.1688791960477829, Val Loss: 0.15333949029445648\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 254: Train Loss: 0.16413171589374542, Val Loss: 0.1538386046886444\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 255: Train Loss: 0.15563273429870605, Val Loss: 0.14818964898586273\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 256: Train Loss: 0.15411494672298431, Val Loss: 0.14561045169830322\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 257: Train Loss: 0.1483883559703827, Val Loss: 0.13299183547496796\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 258: Train Loss: 0.1454864889383316, Val Loss: 0.1346520036458969\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 259: Train Loss: 0.13863609731197357, Val Loss: 0.12446049600839615\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 260: Train Loss: 0.1346990317106247, Val Loss: 0.11847066134214401\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 261: Train Loss: 0.1294657289981842, Val Loss: 0.11807581782341003\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 262: Train Loss: 0.12546533346176147, Val Loss: 0.11648692935705185\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 263: Train Loss: 0.12087836116552353, Val Loss: 0.10234641283750534\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 264: Train Loss: 0.1173785999417305, Val Loss: 0.10646572709083557\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 265: Train Loss: 0.1111864373087883, Val Loss: 0.10179799050092697\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 266: Train Loss: 0.10684387385845184, Val Loss: 0.0976303219795227\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 267: Train Loss: 0.10268950462341309, Val Loss: 0.09469492733478546\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 268: Train Loss: 0.10049930214881897, Val Loss: 0.08708927035331726\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 269: Train Loss: 0.09648069739341736, Val Loss: 0.08816015720367432\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 270: Train Loss: 0.09238839894533157, Val Loss: 0.08413560688495636\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 271: Train Loss: 0.08933074027299881, Val Loss: 0.08301428705453873\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 272: Train Loss: 0.1582963466644287, Val Loss: 0.0884757712483406\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 273: Train Loss: 0.22226008772850037, Val Loss: 0.10520996153354645\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 274: Train Loss: 0.11163624376058578, Val Loss: 0.12576515972614288\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 275: Train Loss: 0.13273946940898895, Val Loss: 0.1409560889005661\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 276: Train Loss: 0.15124042332172394, Val Loss: 0.1583777219057083\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 277: Train Loss: 0.16571760177612305, Val Loss: 0.17649149894714355\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 278: Train Loss: 0.1815275102853775, Val Loss: 0.18286441266536713\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 279: Train Loss: 0.19392745196819305, Val Loss: 0.1937723010778427\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 280: Train Loss: 0.20391429960727692, Val Loss: 0.2077340930700302\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 281: Train Loss: 0.21537388861179352, Val Loss: 0.2188897281885147\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 282: Train Loss: 0.22382523119449615, Val Loss: 0.22521989047527313\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 283: Train Loss: 0.23034504055976868, Val Loss: 0.22697940468788147\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 284: Train Loss: 0.23707088828086853, Val Loss: 0.23162207007408142\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 285: Train Loss: 0.2397674024105072, Val Loss: 0.2368593066930771\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 286: Train Loss: 0.2418808937072754, Val Loss: 0.23665931820869446\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 287: Train Loss: 0.24282875657081604, Val Loss: 0.24180199205875397\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 288: Train Loss: 0.2476819008588791, Val Loss: 0.2346581667661667\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 289: Train Loss: 0.2445724606513977, Val Loss: 0.23620657622814178\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 290: Train Loss: 0.24469135701656342, Val Loss: 0.23375146090984344\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 291: Train Loss: 0.24415259063243866, Val Loss: 0.23146659135818481\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 292: Train Loss: 0.23854346573352814, Val Loss: 0.22709187865257263\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 293: Train Loss: 0.23393844068050385, Val Loss: 0.22250895202159882\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 294: Train Loss: 0.2336418777704239, Val Loss: 0.21925248205661774\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 295: Train Loss: 0.22909381985664368, Val Loss: 0.22148790955543518\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 296: Train Loss: 0.22515569627285004, Val Loss: 0.204880490899086\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 297: Train Loss: 0.2194831669330597, Val Loss: 0.21353763341903687\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 298: Train Loss: 0.21463744342327118, Val Loss: 0.20005346834659576\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 299: Train Loss: 0.20935600996017456, Val Loss: 0.19150294363498688\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 300: Train Loss: 0.20594991743564606, Val Loss: 0.18950282037258148\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 301: Train Loss: 0.20130221545696259, Val Loss: 0.18594929575920105\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 302: Train Loss: 0.19598796963691711, Val Loss: 0.1804531067609787\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 303: Train Loss: 0.18906685709953308, Val Loss: 0.1727139800786972\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 304: Train Loss: 0.18486641347408295, Val Loss: 0.16700080037117004\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 305: Train Loss: 0.1769126057624817, Val Loss: 0.17063651978969574\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 306: Train Loss: 0.1715245097875595, Val Loss: 0.1601271778345108\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 307: Train Loss: 0.1677129566669464, Val Loss: 0.151541605591774\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 308: Train Loss: 0.16121229529380798, Val Loss: 0.14440372586250305\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 309: Train Loss: 0.15419141948223114, Val Loss: 0.1386757344007492\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 310: Train Loss: 0.15096047520637512, Val Loss: 0.13482099771499634\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 311: Train Loss: 0.1445242017507553, Val Loss: 0.12906567752361298\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 312: Train Loss: 0.13771940767765045, Val Loss: 0.1282934695482254\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 313: Train Loss: 0.13381025195121765, Val Loss: 0.12007508426904678\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 314: Train Loss: 0.12986262142658234, Val Loss: 0.11384792625904083\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 315: Train Loss: 0.12546034157276154, Val Loss: 0.11181023716926575\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 316: Train Loss: 0.11851134896278381, Val Loss: 0.10690310597419739\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 317: Train Loss: 0.11557648330926895, Val Loss: 0.1038600355386734\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 318: Train Loss: 0.1108270063996315, Val Loss: 0.09826570749282837\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 319: Train Loss: 0.1063951700925827, Val Loss: 0.09335427731275558\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 320: Train Loss: 0.10174493491649628, Val Loss: 0.09234806895256042\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 321: Train Loss: 0.09826404601335526, Val Loss: 0.09028392285108566\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 322: Train Loss: 0.09517394006252289, Val Loss: 0.08749149739742279\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 323: Train Loss: 0.09022093564271927, Val Loss: 0.07636625319719315\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 324: Train Loss: 0.08816099166870117, Val Loss: 0.08041597157716751\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 325: Train Loss: 0.08350596576929092, Val Loss: 0.07514750957489014\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 326: Train Loss: 0.08096334338188171, Val Loss: 0.07231294363737106\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 327: Train Loss: 0.07790115475654602, Val Loss: 0.06730448454618454\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 328: Train Loss: 0.07395416498184204, Val Loss: 0.06678149849176407\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 329: Train Loss: 0.07174864411354065, Val Loss: 0.06308357417583466\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 330: Train Loss: 0.1295134425163269, Val Loss: 0.09170150011777878\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 331: Train Loss: 0.10188320279121399, Val Loss: 1.9650919437408447\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 332: Train Loss: 0.6911462545394897, Val Loss: 0.11779657751321793\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 333: Train Loss: 0.12900112569332123, Val Loss: 0.10327666997909546\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 334: Train Loss: 0.110758475959301, Val Loss: 0.11074747890233994\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 335: Train Loss: 0.11722391843795776, Val Loss: 0.11792968958616257\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 336: Train Loss: 0.12860225141048431, Val Loss: 0.13411694765090942\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 337: Train Loss: 0.13856473565101624, Val Loss: 0.1400475800037384\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 338: Train Loss: 0.14775389432907104, Val Loss: 0.14733122289180756\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 339: Train Loss: 0.15509071946144104, Val Loss: 0.15206074714660645\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 340: Train Loss: 0.16074834764003754, Val Loss: 0.15984225273132324\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 341: Train Loss: 0.16489596664905548, Val Loss: 0.16473694145679474\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 342: Train Loss: 0.16970889270305634, Val Loss: 0.16725987195968628\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 343: Train Loss: 0.1706143021583557, Val Loss: 0.1705753356218338\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 344: Train Loss: 0.17566919326782227, Val Loss: 0.17051459848880768\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 345: Train Loss: 0.1756957322359085, Val Loss: 0.17407353222370148\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 346: Train Loss: 0.17586949467658997, Val Loss: 0.1761064976453781\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 347: Train Loss: 0.17514526844024658, Val Loss: 0.17156457901000977\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 348: Train Loss: 0.17316122353076935, Val Loss: 0.16602763533592224\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 349: Train Loss: 0.17257654666900635, Val Loss: 0.16667012870311737\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 350: Train Loss: 0.17084957659244537, Val Loss: 0.158901646733284\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 351: Train Loss: 0.16988860070705414, Val Loss: 0.16368456184864044\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 352: Train Loss: 0.16648387908935547, Val Loss: 0.1639237254858017\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 353: Train Loss: 0.16238389909267426, Val Loss: 0.15745465457439423\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 354: Train Loss: 0.16163358092308044, Val Loss: 0.15284980833530426\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 355: Train Loss: 0.15762126445770264, Val Loss: 0.14958079159259796\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 356: Train Loss: 0.15450696647167206, Val Loss: 0.14816546440124512\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 357: Train Loss: 0.14937952160835266, Val Loss: 0.14261503517627716\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 358: Train Loss: 0.1480976790189743, Val Loss: 0.13785293698310852\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 359: Train Loss: 0.14052216708660126, Val Loss: 0.13644103705883026\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 360: Train Loss: 0.13917121291160583, Val Loss: 0.12959368526935577\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 361: Train Loss: 0.1346738487482071, Val Loss: 0.12787769734859467\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 362: Train Loss: 0.1298324167728424, Val Loss: 0.1247425526380539\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 363: Train Loss: 0.12525880336761475, Val Loss: 0.11815148591995239\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 364: Train Loss: 0.12235823273658752, Val Loss: 0.11642049252986908\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 365: Train Loss: 0.11938964575529099, Val Loss: 0.11419732868671417\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 366: Train Loss: 0.1150725930929184, Val Loss: 0.10543692857027054\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 367: Train Loss: 0.11021111160516739, Val Loss: 0.10638944059610367\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 368: Train Loss: 0.1070830225944519, Val Loss: 0.10144908726215363\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 369: Train Loss: 0.10238313674926758, Val Loss: 0.09732046723365784\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 370: Train Loss: 0.09956078231334686, Val Loss: 0.09593687951564789\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 371: Train Loss: 0.09593397378921509, Val Loss: 0.0916268602013588\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 372: Train Loss: 0.09339659661054611, Val Loss: 0.09105328470468521\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 373: Train Loss: 0.09033553302288055, Val Loss: 0.08471550047397614\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 374: Train Loss: 0.08828403800725937, Val Loss: 0.0833740234375\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 375: Train Loss: 0.0836438313126564, Val Loss: 0.07754115760326385\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 376: Train Loss: 0.08086539804935455, Val Loss: 0.07692815363407135\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 377: Train Loss: 0.2418638914823532, Val Loss: 0.08254837989807129\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 378: Train Loss: 0.085618756711483, Val Loss: 0.08927036076784134\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 379: Train Loss: 0.09251115471124649, Val Loss: 0.09150486439466476\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 380: Train Loss: 0.0970945656299591, Val Loss: 0.09934566169977188\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 381: Train Loss: 0.10152939707040787, Val Loss: 0.10197792202234268\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 382: Train Loss: 0.10532257705926895, Val Loss: 0.10760815441608429\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 383: Train Loss: 0.10871351510286331, Val Loss: 0.10721933841705322\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 384: Train Loss: 0.11056610941886902, Val Loss: 0.10891884565353394\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 385: Train Loss: 0.11535057425498962, Val Loss: 0.11155739426612854\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 386: Train Loss: 0.11616583913564682, Val Loss: 0.11011718958616257\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 387: Train Loss: 0.11386294662952423, Val Loss: 0.11022479087114334\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 388: Train Loss: 0.11530310660600662, Val Loss: 0.11332198232412338\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 389: Train Loss: 0.11369027197360992, Val Loss: 0.11217384785413742\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 390: Train Loss: 0.1144692525267601, Val Loss: 0.11154717206954956\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 391: Train Loss: 0.11416017264127731, Val Loss: 0.1087510734796524\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 392: Train Loss: 0.11304408311843872, Val Loss: 0.10789387673139572\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 393: Train Loss: 0.11023569852113724, Val Loss: 0.10911751538515091\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 394: Train Loss: 0.11126705259084702, Val Loss: 0.10627351701259613\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 395: Train Loss: 0.10626095533370972, Val Loss: 0.09890811890363693\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 396: Train Loss: 0.1051991656422615, Val Loss: 0.09964892268180847\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 397: Train Loss: 0.10533791035413742, Val Loss: 0.09793395549058914\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 398: Train Loss: 0.10038671642541885, Val Loss: 0.09450960904359818\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 399: Train Loss: 0.09905273467302322, Val Loss: 0.09496340900659561\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 400: Train Loss: 0.09545490890741348, Val Loss: 0.0897214412689209\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 401: Train Loss: 0.09273239225149155, Val Loss: 0.087782122194767\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 402: Train Loss: 0.09148126095533371, Val Loss: 0.08633743226528168\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 403: Train Loss: 0.08662600815296173, Val Loss: 0.0802847146987915\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 404: Train Loss: 0.08528649061918259, Val Loss: 0.07877692580223083\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 405: Train Loss: 0.08257535099983215, Val Loss: 0.07809590548276901\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 406: Train Loss: 0.07878398150205612, Val Loss: 0.07438429445028305\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 407: Train Loss: 0.07728356122970581, Val Loss: 0.07378920912742615\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 408: Train Loss: 0.07342386990785599, Val Loss: 0.07069317251443863\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 409: Train Loss: 0.07282360643148422, Val Loss: 0.06770112365484238\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 410: Train Loss: 0.07031849771738052, Val Loss: 0.08927131444215775\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 411: Train Loss: 0.06822190433740616, Val Loss: 0.06419740617275238\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 412: Train Loss: 0.06648410856723785, Val Loss: 0.059035152196884155\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 413: Train Loss: 0.06392078101634979, Val Loss: 0.06014062464237213\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 414: Train Loss: 0.062433019280433655, Val Loss: 0.05510692298412323\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 415: Train Loss: 0.14947809278964996, Val Loss: 0.4191384017467499\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 416: Train Loss: 0.06785935908555984, Val Loss: 0.06847479939460754\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 417: Train Loss: 0.07318519800901413, Val Loss: 0.07037411630153656\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 418: Train Loss: 0.07927679270505905, Val Loss: 0.0736304372549057\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 419: Train Loss: 0.08362184464931488, Val Loss: 0.07805661857128143\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 420: Train Loss: 0.08693987131118774, Val Loss: 0.08414000272750854\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 421: Train Loss: 0.08870209753513336, Val Loss: 0.08113735914230347\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 422: Train Loss: 0.09314292669296265, Val Loss: 0.08537885546684265\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 423: Train Loss: 0.09625845402479172, Val Loss: 0.0870576798915863\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 424: Train Loss: 0.09616424143314362, Val Loss: 0.08604337275028229\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 425: Train Loss: 0.09720202535390854, Val Loss: 0.08821409195661545\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 426: Train Loss: 0.09755855798721313, Val Loss: 0.08521559834480286\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 427: Train Loss: 0.09531550854444504, Val Loss: 0.08738505095243454\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 428: Train Loss: 0.24067294597625732, Val Loss: 0.09963712096214294\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 429: Train Loss: 0.11140886694192886, Val Loss: 0.12941403687000275\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 430: Train Loss: 0.14013956487178802, Val Loss: 0.1658155471086502\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 431: Train Loss: 0.17956647276878357, Val Loss: 0.20284782350063324\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 432: Train Loss: 0.2163272500038147, Val Loss: 0.22766710817813873\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 433: Train Loss: 0.24092373251914978, Val Loss: 0.24169865250587463\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 434: Train Loss: 0.2574160695075989, Val Loss: 0.2506503462791443\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 435: Train Loss: 0.2630847692489624, Val Loss: 0.2442612648010254\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 436: Train Loss: 0.26009294390678406, Val Loss: 0.2350432574748993\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 437: Train Loss: 0.2480812668800354, Val Loss: 0.21585974097251892\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 438: Train Loss: 0.22756071388721466, Val Loss: 0.19110535085201263\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 439: Train Loss: 0.20568369328975677, Val Loss: 0.16886964440345764\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 440: Train Loss: 0.18159270286560059, Val Loss: 0.15519727766513824\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 441: Train Loss: 0.16395244002342224, Val Loss: 0.14346975088119507\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 442: Train Loss: 0.15602746605873108, Val Loss: 0.1415500044822693\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 443: Train Loss: 0.14983367919921875, Val Loss: 0.1394299566745758\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 444: Train Loss: 0.14607441425323486, Val Loss: 0.136871799826622\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 445: Train Loss: 0.14536643028259277, Val Loss: 0.12979815900325775\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 446: Train Loss: 0.14045068621635437, Val Loss: 0.134597510099411\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 447: Train Loss: 0.1385200470685959, Val Loss: 0.12835320830345154\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 448: Train Loss: 0.13660268485546112, Val Loss: 0.12247326225042343\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 449: Train Loss: 0.13036853075027466, Val Loss: 0.11987076699733734\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 450: Train Loss: 0.1287454068660736, Val Loss: 0.1212177500128746\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 451: Train Loss: 0.12510336935520172, Val Loss: 0.11112884432077408\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 452: Train Loss: 0.12164656817913055, Val Loss: 0.1131862998008728\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 453: Train Loss: 0.11656247824430466, Val Loss: 0.10661182552576065\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 454: Train Loss: 0.11298948526382446, Val Loss: 0.10444905608892441\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 455: Train Loss: 0.1098548024892807, Val Loss: 0.09973248839378357\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 456: Train Loss: 0.10777128487825394, Val Loss: 0.09352203458547592\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 457: Train Loss: 0.10310468077659607, Val Loss: 0.09737410396337509\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 458: Train Loss: 0.09868945181369781, Val Loss: 0.0937868058681488\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 459: Train Loss: 0.09586317837238312, Val Loss: 0.08641121536493301\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 460: Train Loss: 0.09395231306552887, Val Loss: 0.0837421640753746\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 461: Train Loss: 0.09006558358669281, Val Loss: 0.07889557629823685\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 462: Train Loss: 0.08732055872678757, Val Loss: 0.07986114174127579\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 463: Train Loss: 0.08415132015943527, Val Loss: 0.0763993114233017\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 464: Train Loss: 0.0820942297577858, Val Loss: 0.0700233057141304\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 465: Train Loss: 0.07714086771011353, Val Loss: 0.06949863582849503\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 466: Train Loss: 0.0753779485821724, Val Loss: 0.06896834820508957\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 467: Train Loss: 0.07246069610118866, Val Loss: 0.06682673841714859\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 468: Train Loss: 0.07032989710569382, Val Loss: 0.06400567293167114\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 469: Train Loss: 1.1319102048873901, Val Loss: 0.07458711415529251\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 470: Train Loss: 0.07859664410352707, Val Loss: 0.08547411859035492\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 471: Train Loss: 0.09020884335041046, Val Loss: 0.09235754609107971\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 472: Train Loss: 0.0977337658405304, Val Loss: 0.0996183231472969\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 473: Train Loss: 0.10640096664428711, Val Loss: 0.10852933675050735\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 474: Train Loss: 0.11458579450845718, Val Loss: 0.11814295500516891\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 475: Train Loss: 0.12258247286081314, Val Loss: 0.12038321793079376\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 476: Train Loss: 0.12791158258914948, Val Loss: 0.12493715435266495\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 477: Train Loss: 0.1330331712961197, Val Loss: 0.12941473722457886\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 478: Train Loss: 0.13809549808502197, Val Loss: 0.13675563037395477\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 479: Train Loss: 0.1404811143875122, Val Loss: 0.1355288028717041\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 480: Train Loss: 0.14262399077415466, Val Loss: 0.13685792684555054\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 481: Train Loss: 0.14498715102672577, Val Loss: 0.14338251948356628\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 482: Train Loss: 0.14595258235931396, Val Loss: 0.13965971767902374\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 483: Train Loss: 0.14633403718471527, Val Loss: 0.1356840580701828\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 484: Train Loss: 0.14500656723976135, Val Loss: 0.13661009073257446\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 485: Train Loss: 0.14414791762828827, Val Loss: 0.13457602262496948\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 486: Train Loss: 0.14399006962776184, Val Loss: 0.13120771944522858\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 487: Train Loss: 0.1413058638572693, Val Loss: 0.13223722577095032\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 488: Train Loss: 0.13894100487232208, Val Loss: 0.13060985505580902\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 489: Train Loss: 0.13752257823944092, Val Loss: 0.12770530581474304\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 490: Train Loss: 0.1334371715784073, Val Loss: 0.12434568256139755\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 491: Train Loss: 0.13011901080608368, Val Loss: 0.12412390112876892\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 492: Train Loss: 0.1286270022392273, Val Loss: 0.11652541160583496\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 493: Train Loss: 0.12430983036756516, Val Loss: 0.11643410474061966\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 494: Train Loss: 0.1211550310254097, Val Loss: 0.10649686306715012\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 495: Train Loss: 0.11633650213479996, Val Loss: 0.11262357234954834\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 496: Train Loss: 0.11323259770870209, Val Loss: 1.770446538925171\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 497: Train Loss: 0.11181902885437012, Val Loss: 0.10247711837291718\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 498: Train Loss: 0.10733722895383835, Val Loss: 0.09178213775157928\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 499: Train Loss: 0.1025693342089653, Val Loss: 0.09206540882587433\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 500: Train Loss: 0.09921665489673615, Val Loss: 0.09090849757194519\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 501: Train Loss: 0.09598712623119354, Val Loss: 0.08670834451913834\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 502: Train Loss: 0.09092159569263458, Val Loss: 0.08669356256723404\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 503: Train Loss: 0.08902350068092346, Val Loss: 0.07911350578069687\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 504: Train Loss: 0.08470682799816132, Val Loss: 0.07909917086362839\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 505: Train Loss: 0.08207307755947113, Val Loss: 0.07251901924610138\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 506: Train Loss: 0.07846961915493011, Val Loss: 0.6895281076431274\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 507: Train Loss: 0.07579993456602097, Val Loss: 0.06925562769174576\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 508: Train Loss: 0.0724179744720459, Val Loss: 0.06762160360813141\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 509: Train Loss: 0.07047083228826523, Val Loss: 0.059278491884469986\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 510: Train Loss: 0.06658636033535004, Val Loss: 0.05946160480380058\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 511: Train Loss: 0.06499874591827393, Val Loss: 0.05809870734810829\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 512: Train Loss: 0.0625198557972908, Val Loss: 0.0552060641348362\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 513: Train Loss: 0.059881992638111115, Val Loss: 0.054145313799381256\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 514: Train Loss: 1.18378746509552, Val Loss: 0.06019696593284607\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 515: Train Loss: 0.06262996047735214, Val Loss: 0.063896045088768\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 516: Train Loss: 0.2650885581970215, Val Loss: 0.07579291611909866\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 517: Train Loss: 0.08143001794815063, Val Loss: 0.08618495613336563\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 518: Train Loss: 0.0917055681347847, Val Loss: 0.09445980936288834\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 519: Train Loss: 0.10150516033172607, Val Loss: 0.1035977229475975\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 520: Train Loss: 0.10940028727054596, Val Loss: 0.11288878321647644\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 521: Train Loss: 0.11902725696563721, Val Loss: 0.12082917988300323\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 522: Train Loss: 0.12543582916259766, Val Loss: 0.12727957963943481\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 523: Train Loss: 0.1314886063337326, Val Loss: 0.1337994933128357\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 524: Train Loss: 0.1351727843284607, Val Loss: 0.6722703576087952\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 525: Train Loss: 0.14041605591773987, Val Loss: 0.13268546760082245\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 526: Train Loss: 0.1427658200263977, Val Loss: 0.14302179217338562\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 527: Train Loss: 0.14618173241615295, Val Loss: 4.916752815246582\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 528: Train Loss: 0.14461679756641388, Val Loss: 0.13887788355350494\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 529: Train Loss: 0.14681319892406464, Val Loss: 2.8265960216522217\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 530: Train Loss: 0.14688123762607574, Val Loss: 0.14283372461795807\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 531: Train Loss: 0.14780165255069733, Val Loss: 0.14079436659812927\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 532: Train Loss: 0.14531844854354858, Val Loss: 0.1357494443655014\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 533: Train Loss: 0.14276571571826935, Val Loss: 0.13776752352714539\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 534: Train Loss: 0.14325645565986633, Val Loss: 5.135187149047852\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 535: Train Loss: 0.14010024070739746, Val Loss: 0.1322704255580902\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 536: Train Loss: 0.13879595696926117, Val Loss: 0.12791995704174042\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 537: Train Loss: 0.1336403638124466, Val Loss: 0.12685035169124603\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 538: Train Loss: 0.13122807443141937, Val Loss: 3.1774890422821045\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 539: Train Loss: 0.12976785004138947, Val Loss: 0.11749999970197678\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 540: Train Loss: 0.12481816112995148, Val Loss: 0.12072715163230896\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 541: Train Loss: 0.12188654392957687, Val Loss: 5.1117048263549805\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 542: Train Loss: 0.11761483550071716, Val Loss: 0.11241648346185684\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 543: Train Loss: 0.11573220789432526, Val Loss: 0.10715673863887787\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 544: Train Loss: 0.11174716800451279, Val Loss: 0.1063755676150322\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 545: Train Loss: 0.10797305405139923, Val Loss: 0.09942836314439774\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 546: Train Loss: 0.10343065112829208, Val Loss: 4.03465461730957\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 547: Train Loss: 0.10097602009773254, Val Loss: 6.5678510665893555\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 548: Train Loss: 0.09653733670711517, Val Loss: 5.090339183807373\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 549: Train Loss: 0.09328025579452515, Val Loss: 0.08632944524288177\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 550: Train Loss: 0.09130831062793732, Val Loss: 0.08486620336771011\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 551: Train Loss: 0.08854326605796814, Val Loss: 0.07849416136741638\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 552: Train Loss: 0.08332254737615585, Val Loss: 0.07737419009208679\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 553: Train Loss: 0.08189046382904053, Val Loss: 0.07181589305400848\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 554: Train Loss: 0.07853667438030243, Val Loss: 0.06993787735700607\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 555: Train Loss: 0.07485181093215942, Val Loss: 0.5130849480628967\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 556: Train Loss: 0.07261671870946884, Val Loss: 5.065228462219238\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 557: Train Loss: 0.06903284043073654, Val Loss: 0.05961877480149269\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 558: Train Loss: 0.0670112743973732, Val Loss: 2.536527395248413\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 559: Train Loss: 0.06456854939460754, Val Loss: 4.796306610107422\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 560: Train Loss: 0.06244273856282234, Val Loss: 0.0569082535803318\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 561: Train Loss: 0.059812046587467194, Val Loss: 1.1192113161087036\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 562: Train Loss: 0.05811451002955437, Val Loss: 3.403247833251953\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 563: Train Loss: 0.0559992678463459, Val Loss: 5.050325870513916\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 564: Train Loss: 0.05446586757898331, Val Loss: 0.04945576936006546\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 565: Train Loss: 0.05224999412894249, Val Loss: 0.04836739972233772\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 566: Train Loss: 0.05187426880002022, Val Loss: 5.04639196395874\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 567: Train Loss: 0.04856549948453903, Val Loss: 0.3306722044944763\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 568: Train Loss: 0.04789804294705391, Val Loss: 0.045406535267829895\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 569: Train Loss: 0.04661519080400467, Val Loss: 0.8867325782775879\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 570: Train Loss: 0.04481768608093262, Val Loss: 5.0412373542785645\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 571: Train Loss: 0.04366869106888771, Val Loss: 0.03881973400712013\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 572: Train Loss: 0.043251883238554, Val Loss: 0.039097752422094345\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 573: Train Loss: 0.04217417165637016, Val Loss: 0.03855731710791588\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 574: Train Loss: 0.04146376624703407, Val Loss: 0.035595595836639404\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 575: Train Loss: 0.04001850262284279, Val Loss: 5.281628131866455\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 576: Train Loss: 0.03930249065160751, Val Loss: 0.03426723554730415\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 577: Train Loss: 0.26426637172698975, Val Loss: 0.03939296305179596\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 578: Train Loss: 0.04334937036037445, Val Loss: 1.7836729288101196\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 579: Train Loss: 0.0469597727060318, Val Loss: 1.7373313903808594\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 580: Train Loss: 0.051667191088199615, Val Loss: 3.9740214347839355\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 581: Train Loss: 0.05608082562685013, Val Loss: 0.05473916605114937\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 582: Train Loss: 0.061013199388980865, Val Loss: 0.058180760592222214\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 583: Train Loss: 0.06443692743778229, Val Loss: 0.06176161766052246\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 584: Train Loss: 0.06862612813711166, Val Loss: 0.06563802808523178\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 585: Train Loss: 0.07038993388414383, Val Loss: 0.06962980329990387\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 586: Train Loss: 0.07294672727584839, Val Loss: 0.06971865147352219\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 587: Train Loss: 0.07514917850494385, Val Loss: 0.07028073817491531\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 588: Train Loss: 0.0771908313035965, Val Loss: 0.07515739649534225\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 589: Train Loss: 0.0781165212392807, Val Loss: 0.07612764090299606\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 590: Train Loss: 0.07832805812358856, Val Loss: 0.07446689903736115\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 591: Train Loss: 0.08018889278173447, Val Loss: 0.07445701211690903\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 592: Train Loss: 0.07818165421485901, Val Loss: 0.07264002412557602\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 593: Train Loss: 0.07860006392002106, Val Loss: 0.07062175124883652\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 594: Train Loss: 0.0797484815120697, Val Loss: 0.07338311523199081\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 595: Train Loss: 0.0792103111743927, Val Loss: 0.07251836359500885\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 596: Train Loss: 0.07684563100337982, Val Loss: 0.07255899906158447\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 597: Train Loss: 0.07492396980524063, Val Loss: 0.07238010317087173\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 598: Train Loss: 0.0764840766787529, Val Loss: 0.06980891525745392\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 599: Train Loss: 0.07374740391969681, Val Loss: 0.06853754818439484\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 600: Train Loss: 0.07261329889297485, Val Loss: 0.06533690541982651\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 601: Train Loss: 0.06976539641618729, Val Loss: 0.06295300275087357\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 602: Train Loss: 0.0694815069437027, Val Loss: 2.3297605514526367\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 603: Train Loss: 0.06787201762199402, Val Loss: 0.061699189245700836\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 604: Train Loss: 0.06719106435775757, Val Loss: 0.056507352739572525\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 605: Train Loss: 0.06635107100009918, Val Loss: 5.057872772216797\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 606: Train Loss: 0.06449568271636963, Val Loss: 0.05504686385393143\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 607: Train Loss: 0.06128295138478279, Val Loss: 0.0579318031668663\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 608: Train Loss: 0.060031503438949585, Val Loss: 0.0530133955180645\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 609: Train Loss: 0.059900976717472076, Val Loss: 0.05365341529250145\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 610: Train Loss: 0.05682353302836418, Val Loss: 0.05170627683401108\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 611: Train Loss: 0.05434855446219444, Val Loss: 0.04963180050253868\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 612: Train Loss: 0.0535370297729969, Val Loss: 0.05018216744065285\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 613: Train Loss: 0.05121996998786926, Val Loss: 0.04783575236797333\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 614: Train Loss: 0.05116759240627289, Val Loss: 0.046358440071344376\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 615: Train Loss: 0.049602121114730835, Val Loss: 0.04514148831367493\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 616: Train Loss: 0.04764781892299652, Val Loss: 5.043793678283691\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 617: Train Loss: 0.04654704034328461, Val Loss: 0.0403159037232399\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 618: Train Loss: 0.046313125640153885, Val Loss: 0.7945537567138672\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 619: Train Loss: 0.043693479150533676, Val Loss: 5.038919448852539\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 620: Train Loss: 0.04377821460366249, Val Loss: 0.038520656526088715\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 621: Train Loss: 0.0432894341647625, Val Loss: 0.037515852600336075\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 622: Train Loss: 0.04224185645580292, Val Loss: 0.038322813808918\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 623: Train Loss: 1.5709667205810547, Val Loss: 5.040441989898682\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 624: Train Loss: 0.04482748731970787, Val Loss: 0.044063203036785126\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 625: Train Loss: 0.047535356134176254, Val Loss: 0.04823510721325874\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 626: Train Loss: 0.05091019347310066, Val Loss: 0.05074932426214218\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 627: Train Loss: 0.05468037724494934, Val Loss: 0.052633676677942276\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 628: Train Loss: 0.057080887258052826, Val Loss: 0.05533793941140175\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 629: Train Loss: 0.05979682505130768, Val Loss: 0.05760945752263069\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 630: Train Loss: 0.06156589835882187, Val Loss: 0.058927956968545914\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 631: Train Loss: 0.06236620992422104, Val Loss: 0.05930376797914505\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 632: Train Loss: 0.06432411819696426, Val Loss: 0.0638536885380745\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 633: Train Loss: 0.06562310457229614, Val Loss: 0.0635262131690979\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 634: Train Loss: 0.06480589509010315, Val Loss: 0.06324726343154907\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 635: Train Loss: 0.06688553839921951, Val Loss: 0.061942555010318756\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 636: Train Loss: 0.06614377349615097, Val Loss: 0.06215613707900047\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 637: Train Loss: 0.06635601818561554, Val Loss: 0.05952466279268265\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 638: Train Loss: 0.06573301553726196, Val Loss: 0.061492227017879486\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 639: Train Loss: 0.064999520778656, Val Loss: 0.059730637818574905\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 640: Train Loss: 0.06530194729566574, Val Loss: 0.06129095330834389\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 641: Train Loss: 0.06440535932779312, Val Loss: 0.059024628251791\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 642: Train Loss: 0.06270657479763031, Val Loss: 2.848836660385132\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 643: Train Loss: 0.0625179335474968, Val Loss: 1.1472582817077637\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 644: Train Loss: 0.06229458004236221, Val Loss: 0.05663018673658371\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 645: Train Loss: 0.06103720888495445, Val Loss: 0.0551871620118618\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 646: Train Loss: 0.27656278014183044, Val Loss: 0.06105215474963188\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 647: Train Loss: 0.06743551790714264, Val Loss: 0.07379665225744247\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 648: Train Loss: 0.08051279932260513, Val Loss: 0.08997782319784164\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 649: Train Loss: 0.09528648108243942, Val Loss: 0.10159006714820862\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 650: Train Loss: 0.11042780429124832, Val Loss: 2.041031837463379\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 651: Train Loss: 0.11847727745771408, Val Loss: 0.11591792851686478\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 652: Train Loss: 0.12436676770448685, Val Loss: 0.11545298248529434\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 653: Train Loss: 0.12296248227357864, Val Loss: 3.2846617698669434\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 654: Train Loss: 0.11914516985416412, Val Loss: 0.10487925261259079\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 655: Train Loss: 0.11227016896009445, Val Loss: 0.09849082678556442\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 656: Train Loss: 0.10561732947826385, Val Loss: 0.09521535038948059\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 657: Train Loss: 0.10072553157806396, Val Loss: 0.09454526752233505\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 658: Train Loss: 0.09860926866531372, Val Loss: 5.0937676429748535\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 659: Train Loss: 0.09761350601911545, Val Loss: 0.09380464255809784\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 660: Train Loss: 0.09641813486814499, Val Loss: 2.9328665733337402\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 661: Train Loss: 0.09627069532871246, Val Loss: 0.09202168881893158\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 662: Train Loss: 0.09345787018537521, Val Loss: 0.08978573232889175\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 663: Train Loss: 0.0929379090666771, Val Loss: 0.08633493632078171\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 664: Train Loss: 0.09108275920152664, Val Loss: 0.08849076181650162\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 665: Train Loss: 0.0893232598900795, Val Loss: 0.082770936191082\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 666: Train Loss: 0.08836136013269424, Val Loss: 3.5175974369049072\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 667: Train Loss: 0.08488535135984421, Val Loss: 0.0805160328745842\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 668: Train Loss: 0.08489309996366501, Val Loss: 2.5892326831817627\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 669: Train Loss: 0.08233524858951569, Val Loss: 0.4852435886859894\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 670: Train Loss: 0.08014406263828278, Val Loss: 0.07329653948545456\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 671: Train Loss: 0.07821784168481827, Val Loss: 0.07193035632371902\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 672: Train Loss: 0.07620837539434433, Val Loss: 0.07063683122396469\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 673: Train Loss: 0.07234466075897217, Val Loss: 5.064846992492676\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 674: Train Loss: 0.07165306806564331, Val Loss: 0.06516657024621964\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 675: Train Loss: 0.0680316910147667, Val Loss: 0.06429669260978699\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 676: Train Loss: 0.06806936860084534, Val Loss: 0.062192756682634354\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 677: Train Loss: 0.06444919854402542, Val Loss: 0.06096027418971062\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 678: Train Loss: 0.06355231255292892, Val Loss: 0.059038493782281876\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 679: Train Loss: 0.06169971078634262, Val Loss: 0.05454149842262268\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 680: Train Loss: 0.058861006051301956, Val Loss: 5.058487415313721\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 681: Train Loss: 0.05715946853160858, Val Loss: 4.7222514152526855\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 682: Train Loss: 0.054634809494018555, Val Loss: 1.2756749391555786\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 683: Train Loss: 0.052241623401641846, Val Loss: 0.04940634220838547\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 684: Train Loss: 0.05047779157757759, Val Loss: 0.30833500623703003\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 685: Train Loss: 0.049544211477041245, Val Loss: 5.045178413391113\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 686: Train Loss: 0.048765040934085846, Val Loss: 0.041142139583826065\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 687: Train Loss: 0.04738938808441162, Val Loss: 0.04108472168445587\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 688: Train Loss: 0.3481043577194214, Val Loss: 5.047529697418213\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 689: Train Loss: 0.04968735948204994, Val Loss: 0.05448276549577713\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 690: Train Loss: 0.05775892734527588, Val Loss: 0.06284690648317337\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 691: Train Loss: 0.06401623785495758, Val Loss: 0.07152251154184341\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 692: Train Loss: 0.07189732044935226, Val Loss: 0.07819251716136932\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 693: Train Loss: 0.08013507723808289, Val Loss: 0.08293723315000534\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 694: Train Loss: 0.08431129902601242, Val Loss: 0.08886466175317764\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 695: Train Loss: 0.09043603390455246, Val Loss: 0.09288757294416428\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 696: Train Loss: 0.093506820499897, Val Loss: 0.09691797941923141\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 697: Train Loss: 0.09793488681316376, Val Loss: 0.10257317870855331\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 698: Train Loss: 0.10130266100168228, Val Loss: 0.09645411372184753\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 699: Train Loss: 0.10653171688318253, Val Loss: 0.10483860969543457\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 700: Train Loss: 0.10684715956449509, Val Loss: 0.1042192131280899\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 701: Train Loss: 0.10773995518684387, Val Loss: 0.10404323041439056\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 702: Train Loss: 0.11004552245140076, Val Loss: 0.10747126489877701\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 703: Train Loss: 0.10825076699256897, Val Loss: 0.10499505698680878\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 704: Train Loss: 0.10919283330440521, Val Loss: 0.10707366466522217\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 705: Train Loss: 0.10658304393291473, Val Loss: 0.1064843237400055\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 706: Train Loss: 0.1069132387638092, Val Loss: 0.10092614591121674\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 707: Train Loss: 0.1053210124373436, Val Loss: 0.10233836621046066\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 708: Train Loss: 0.10543634742498398, Val Loss: 0.09936821460723877\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 709: Train Loss: 0.10306794941425323, Val Loss: 0.1002851352095604\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 710: Train Loss: 0.09990231692790985, Val Loss: 0.09517921507358551\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 711: Train Loss: 0.09954404830932617, Val Loss: 0.0950234979391098\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 712: Train Loss: 0.09612444043159485, Val Loss: 0.09222176671028137\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 713: Train Loss: 0.09300225228071213, Val Loss: 0.0884159728884697\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 714: Train Loss: 0.09011221677064896, Val Loss: 0.08876865357160568\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 715: Train Loss: 0.08849971741437912, Val Loss: 0.08414407074451447\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 716: Train Loss: 0.08756029605865479, Val Loss: 0.08034093677997589\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 717: Train Loss: 0.08280032873153687, Val Loss: 0.07874128967523575\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 718: Train Loss: 0.07941123843193054, Val Loss: 0.07741288840770721\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 719: Train Loss: 0.07822050899267197, Val Loss: 0.0751647874712944\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 720: Train Loss: 0.07501685619354248, Val Loss: 0.07210352271795273\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 721: Train Loss: 0.07407034933567047, Val Loss: 0.06984516978263855\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 722: Train Loss: 0.07154328376054764, Val Loss: 0.0662725493311882\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 723: Train Loss: 0.06744739413261414, Val Loss: 0.0639428198337555\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 724: Train Loss: 0.06612202525138855, Val Loss: 0.06460166722536087\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 725: Train Loss: 0.0640888586640358, Val Loss: 0.06254179030656815\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 726: Train Loss: 0.062337711453437805, Val Loss: 0.14936387538909912\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 727: Train Loss: 0.060845501720905304, Val Loss: 0.05681914836168289\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 728: Train Loss: 0.24138493835926056, Val Loss: 0.07311156392097473\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 729: Train Loss: 0.07478640973567963, Val Loss: 0.0904233381152153\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 730: Train Loss: 0.09291080385446548, Val Loss: 0.10823031514883041\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 731: Train Loss: 0.11201667040586472, Val Loss: 0.1274479329586029\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 732: Train Loss: 0.1297440528869629, Val Loss: 0.1477411836385727\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 733: Train Loss: 0.14613588154315948, Val Loss: 0.16407865285873413\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 734: Train Loss: 0.16241177916526794, Val Loss: 0.17686769366264343\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 735: Train Loss: 0.17599335312843323, Val Loss: 0.18985839188098907\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 736: Train Loss: 0.18888752162456512, Val Loss: 0.1978963017463684\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 737: Train Loss: 0.2005895972251892, Val Loss: 0.20495446026325226\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 738: Train Loss: 0.2096041738986969, Val Loss: 0.21598896384239197\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 739: Train Loss: 0.21512694656848907, Val Loss: 0.21836303174495697\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 740: Train Loss: 0.222777858376503, Val Loss: 0.22509679198265076\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 741: Train Loss: 0.2260904759168625, Val Loss: 0.2262185662984848\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 742: Train Loss: 0.2287472039461136, Val Loss: 0.22692808508872986\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 743: Train Loss: 0.23141346871852875, Val Loss: 0.2286340445280075\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 744: Train Loss: 0.2344236820936203, Val Loss: 0.234141007065773\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 745: Train Loss: 0.23308202624320984, Val Loss: 0.2330615222454071\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 746: Train Loss: 0.2330789566040039, Val Loss: 0.22884659469127655\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 747: Train Loss: 0.2320113629102707, Val Loss: 0.22729076445102692\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 748: Train Loss: 0.2286624014377594, Val Loss: 0.22254996001720428\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 749: Train Loss: 0.22712700068950653, Val Loss: 0.21979694068431854\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 750: Train Loss: 0.22237206995487213, Val Loss: 0.22415561974048615\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 751: Train Loss: 0.2213820368051529, Val Loss: 0.2176584005355835\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 752: Train Loss: 0.21745137870311737, Val Loss: 0.21020463109016418\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 753: Train Loss: 0.2111850529909134, Val Loss: 0.2059623748064041\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 754: Train Loss: 0.20794740319252014, Val Loss: 0.20372392237186432\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 755: Train Loss: 0.2057282030582428, Val Loss: 0.1989733874797821\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 756: Train Loss: 0.1979459673166275, Val Loss: 0.19030466675758362\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 757: Train Loss: 0.19317732751369476, Val Loss: 0.18344038724899292\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 758: Train Loss: 0.1882435530424118, Val Loss: 0.18354125320911407\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 759: Train Loss: 0.18228013813495636, Val Loss: 0.17833662033081055\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 760: Train Loss: 0.17655713856220245, Val Loss: 0.17075742781162262\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 761: Train Loss: 0.17252467572689056, Val Loss: 0.16594290733337402\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 762: Train Loss: 0.16826388239860535, Val Loss: 0.15733960270881653\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 763: Train Loss: 0.16220875084400177, Val Loss: 0.1534329503774643\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 764: Train Loss: 0.1549587845802307, Val Loss: 0.14431320130825043\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 765: Train Loss: 0.1506643444299698, Val Loss: 0.14309938251972198\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 766: Train Loss: 0.14479415118694305, Val Loss: 0.13734020292758942\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 767: Train Loss: 0.14061668515205383, Val Loss: 0.13034109771251678\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 768: Train Loss: 0.1340535283088684, Val Loss: 0.12733054161071777\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 769: Train Loss: 0.129513218998909, Val Loss: 0.12394294887781143\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 770: Train Loss: 0.12370123714208603, Val Loss: 0.1162053644657135\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 771: Train Loss: 0.11872131377458572, Val Loss: 0.11274342983961105\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 772: Train Loss: 0.11665412038564682, Val Loss: 0.10913057625293732\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 773: Train Loss: 0.11076405644416809, Val Loss: 0.10433091968297958\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 774: Train Loss: 0.10488128662109375, Val Loss: 0.10149821639060974\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 775: Train Loss: 0.10147521644830704, Val Loss: 0.09424196183681488\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 776: Train Loss: 0.09752646833658218, Val Loss: 0.09209618717432022\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 777: Train Loss: 0.09355546534061432, Val Loss: 0.08757584542036057\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 778: Train Loss: 0.08993106335401535, Val Loss: 0.0844530239701271\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 779: Train Loss: 0.08613084256649017, Val Loss: 0.08175542205572128\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 780: Train Loss: 0.08134578168392181, Val Loss: 0.07949863374233246\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 781: Train Loss: 0.07961756736040115, Val Loss: 0.07565078139305115\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 782: Train Loss: 0.07555139064788818, Val Loss: 0.06860125809907913\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 783: Train Loss: 0.07289383560419083, Val Loss: 0.06977281719446182\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 784: Train Loss: 0.06959853321313858, Val Loss: 0.06515918672084808\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 785: Train Loss: 0.06771137565374374, Val Loss: 0.06274118274450302\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 786: Train Loss: 0.06558315455913544, Val Loss: 0.06210100278258324\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 787: Train Loss: 0.06292702257633209, Val Loss: 0.05924350023269653\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 788: Train Loss: 0.06029544025659561, Val Loss: 0.05910812318325043\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 789: Train Loss: 0.058688726276159286, Val Loss: 0.05604613199830055\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 790: Train Loss: 0.05576484277844429, Val Loss: 0.05425463244318962\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 791: Train Loss: 0.05452457815408707, Val Loss: 0.052599262446165085\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 792: Train Loss: 0.052097320556640625, Val Loss: 0.05179869383573532\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 793: Train Loss: 0.7223629355430603, Val Loss: 0.056541454046964645\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 794: Train Loss: 0.05574887618422508, Val Loss: 0.06172389164566994\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 795: Train Loss: 0.06278248131275177, Val Loss: 0.06690771132707596\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 796: Train Loss: 0.0694199651479721, Val Loss: 0.06968972831964493\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 797: Train Loss: 0.07431264221668243, Val Loss: 0.07585562020540237\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 798: Train Loss: 0.07832685112953186, Val Loss: 0.07936383783817291\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 799: Train Loss: 0.0821462944149971, Val Loss: 0.08555147051811218\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 800: Train Loss: 0.08648892492055893, Val Loss: 0.08994628489017487\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 801: Train Loss: 0.08923721313476562, Val Loss: 0.09206480532884598\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 802: Train Loss: 0.09225223958492279, Val Loss: 0.09378592669963837\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 803: Train Loss: 0.0946144387125969, Val Loss: 0.09517647325992584\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 804: Train Loss: 0.09584712237119675, Val Loss: 0.09372355788946152\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 805: Train Loss: 0.09753409028053284, Val Loss: 0.09629156440496445\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 806: Train Loss: 0.09612371772527695, Val Loss: 0.0946517288684845\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 807: Train Loss: 0.0963037982583046, Val Loss: 0.09320613741874695\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 808: Train Loss: 0.09714942425489426, Val Loss: 0.09428027272224426\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 809: Train Loss: 0.09560275077819824, Val Loss: 0.09041041880846024\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 810: Train Loss: 0.09629664570093155, Val Loss: 0.09320230782032013\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 811: Train Loss: 0.0929030254483223, Val Loss: 0.08842532336711884\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 812: Train Loss: 0.09150170534849167, Val Loss: 0.09062038362026215\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 813: Train Loss: 0.09115248173475266, Val Loss: 0.08812294155359268\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 814: Train Loss: 0.08843337744474411, Val Loss: 0.08208249509334564\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 815: Train Loss: 0.08690056204795837, Val Loss: 0.08168675750494003\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 816: Train Loss: 0.08411265164613724, Val Loss: 0.08174431324005127\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 817: Train Loss: 0.08153261244297028, Val Loss: 0.08075861632823944\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 818: Train Loss: 0.07999591529369354, Val Loss: 0.07534878700971603\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 819: Train Loss: 0.07896527647972107, Val Loss: 0.07425765693187714\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 820: Train Loss: 0.07657632231712341, Val Loss: 0.07200734317302704\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 821: Train Loss: 0.07317793369293213, Val Loss: 0.06708261370658875\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 822: Train Loss: 0.07075070589780807, Val Loss: 0.06795990467071533\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 823: Train Loss: 0.06890695542097092, Val Loss: 0.06667311489582062\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 824: Train Loss: 0.067853644490242, Val Loss: 0.06450499594211578\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 825: Train Loss: 0.06552509218454361, Val Loss: 0.06324604898691177\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 826: Train Loss: 0.06150777265429497, Val Loss: 0.057316944003105164\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 827: Train Loss: 0.0617649182677269, Val Loss: 0.058600980788469315\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 828: Train Loss: 0.058604318648576736, Val Loss: 0.05720090493559837\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 829: Train Loss: 0.057930462062358856, Val Loss: 0.054226379841566086\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 830: Train Loss: 0.05523281544446945, Val Loss: 0.0497189536690712\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 831: Train Loss: 0.051328472793102264, Val Loss: 0.04851348698139191\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 832: Train Loss: 0.052023254334926605, Val Loss: 0.04813528433442116\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 833: Train Loss: 1.281992793083191, Val Loss: 0.05639643222093582\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 834: Train Loss: 0.057378072291612625, Val Loss: 0.06305135786533356\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 835: Train Loss: 0.06615564972162247, Val Loss: 0.07042032480239868\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 836: Train Loss: 0.07240288704633713, Val Loss: 0.07679180055856705\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 837: Train Loss: 0.07984581589698792, Val Loss: 0.0838317945599556\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 838: Train Loss: 0.08573403209447861, Val Loss: 0.08655232936143875\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 839: Train Loss: 0.09159494936466217, Val Loss: 0.08805648982524872\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 840: Train Loss: 0.09511060267686844, Val Loss: 0.09703977406024933\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 841: Train Loss: 0.09944726526737213, Val Loss: 0.10320533812046051\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 842: Train Loss: 0.10227914899587631, Val Loss: 0.10099875926971436\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 843: Train Loss: 0.10605229437351227, Val Loss: 0.10777272284030914\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 844: Train Loss: 0.10665569454431534, Val Loss: 0.10900888592004776\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 845: Train Loss: 0.10851794481277466, Val Loss: 0.10538983345031738\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 846: Train Loss: 0.10917454212903976, Val Loss: 0.10395843535661697\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 847: Train Loss: 0.10727779567241669, Val Loss: 0.10332563519477844\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 848: Train Loss: 0.10741042345762253, Val Loss: 0.10523752868175507\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 849: Train Loss: 0.10695767402648926, Val Loss: 0.10277548432350159\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 850: Train Loss: 0.10495026409626007, Val Loss: 0.10014359652996063\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 851: Train Loss: 0.1043715551495552, Val Loss: 0.09944230318069458\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 852: Train Loss: 0.10241688787937164, Val Loss: 0.09777656942605972\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 853: Train Loss: 0.10066215693950653, Val Loss: 0.09644295275211334\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 854: Train Loss: 0.09791059046983719, Val Loss: 0.09354228526353836\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 855: Train Loss: 0.09655803442001343, Val Loss: 0.09081820398569107\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 856: Train Loss: 0.09384109079837799, Val Loss: 0.08493609726428986\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 857: Train Loss: 0.09226558357477188, Val Loss: 0.08675608038902283\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 858: Train Loss: 0.088625468313694, Val Loss: 0.0821569636464119\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 859: Train Loss: 0.0872955471277237, Val Loss: 0.07702962309122086\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 860: Train Loss: 0.08336243778467178, Val Loss: 0.07739207148551941\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 861: Train Loss: 0.08040733635425568, Val Loss: 0.07394500821828842\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 862: Train Loss: 0.07741750776767731, Val Loss: 0.07352966070175171\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 863: Train Loss: 0.07429483532905579, Val Loss: 0.0691990926861763\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 864: Train Loss: 0.07153669744729996, Val Loss: 0.06591124087572098\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 865: Train Loss: 0.07072091847658157, Val Loss: 0.06440490484237671\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 866: Train Loss: 0.06744721531867981, Val Loss: 0.06237311661243439\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 867: Train Loss: 0.06476712226867676, Val Loss: 0.05776058882474899\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 868: Train Loss: 0.06178109347820282, Val Loss: 0.05783615633845329\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 869: Train Loss: 0.06001714617013931, Val Loss: 0.05546565726399422\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 870: Train Loss: 0.057602375745773315, Val Loss: 0.053065743297338486\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 871: Train Loss: 0.05629156902432442, Val Loss: 0.04970201477408409\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 872: Train Loss: 0.0540008544921875, Val Loss: 0.04906095936894417\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 873: Train Loss: 0.05238713324069977, Val Loss: 0.049150288105010986\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 874: Train Loss: 0.05053539574146271, Val Loss: 0.045166779309511185\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 875: Train Loss: 0.0480450838804245, Val Loss: 0.045367930084466934\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 876: Train Loss: 0.04721709340810776, Val Loss: 0.04214850813150406\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 877: Train Loss: 0.04465193301439285, Val Loss: 0.03940381854772568\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 878: Train Loss: 0.043438512831926346, Val Loss: 0.039423760026693344\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 879: Train Loss: 0.04330713301897049, Val Loss: 0.03992028906941414\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 880: Train Loss: 0.041840873658657074, Val Loss: 0.03850698843598366\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 881: Train Loss: 0.038995299488306046, Val Loss: 0.037939876317977905\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 882: Train Loss: 0.03909727558493614, Val Loss: 0.034745197743177414\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 883: Train Loss: 0.03801348805427551, Val Loss: 0.03431636095046997\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 884: Train Loss: 0.037334948778152466, Val Loss: 0.035179540514945984\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 885: Train Loss: 0.5509554147720337, Val Loss: 0.04355292767286301\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 886: Train Loss: 0.04763544350862503, Val Loss: 0.05880723521113396\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 887: Train Loss: 0.062269020825624466, Val Loss: 0.07560989260673523\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 888: Train Loss: 0.07979012280702591, Val Loss: 0.09029151499271393\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 889: Train Loss: 0.09514015167951584, Val Loss: 0.1064423993229866\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 890: Train Loss: 0.11122675240039825, Val Loss: 0.12105658650398254\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 891: Train Loss: 0.12677660584449768, Val Loss: 0.1350451111793518\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 892: Train Loss: 0.13935860991477966, Val Loss: 0.14825573563575745\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 893: Train Loss: 0.15042582154273987, Val Loss: 0.1564972698688507\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 894: Train Loss: 0.16217443346977234, Val Loss: 0.16471758484840393\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 895: Train Loss: 0.16956642270088196, Val Loss: 0.17272305488586426\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 896: Train Loss: 0.17761844396591187, Val Loss: 0.17587465047836304\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 897: Train Loss: 0.1824091225862503, Val Loss: 0.18338440358638763\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 898: Train Loss: 0.18571822345256805, Val Loss: 0.18567807972431183\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 899: Train Loss: 0.19171006977558136, Val Loss: 0.1889532059431076\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 900: Train Loss: 0.19242802262306213, Val Loss: 0.1904619187116623\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 901: Train Loss: 0.19661454856395721, Val Loss: 0.19197452068328857\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 902: Train Loss: 0.19432032108306885, Val Loss: 0.1906515210866928\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 903: Train Loss: 0.19517146050930023, Val Loss: 0.18771997094154358\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 904: Train Loss: 0.19513626396656036, Val Loss: 0.18605084717273712\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 905: Train Loss: 0.19355987012386322, Val Loss: 0.18386395275592804\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 906: Train Loss: 0.1908518522977829, Val Loss: 0.17943346500396729\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 907: Train Loss: 0.1884097307920456, Val Loss: 0.18145664036273956\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 908: Train Loss: 0.18758481740951538, Val Loss: 0.17684808373451233\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 909: Train Loss: 0.18191824853420258, Val Loss: 0.17542752623558044\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 910: Train Loss: 0.18222588300704956, Val Loss: 0.17376822233200073\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 911: Train Loss: 0.1763167530298233, Val Loss: 0.16449807584285736\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 912: Train Loss: 0.17019228637218475, Val Loss: 0.161774143576622\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 913: Train Loss: 0.1678282916545868, Val Loss: 0.16107672452926636\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 914: Train Loss: 0.16423219442367554, Val Loss: 0.15377414226531982\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 915: Train Loss: 0.15996073186397552, Val Loss: 0.14812493324279785\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 916: Train Loss: 0.15571123361587524, Val Loss: 0.14301657676696777\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 917: Train Loss: 0.15174274146556854, Val Loss: 0.13937756419181824\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 918: Train Loss: 0.14665363729000092, Val Loss: 0.13455069065093994\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 919: Train Loss: 0.1420619636774063, Val Loss: 0.1325024664402008\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 920: Train Loss: 0.13613781332969666, Val Loss: 0.1261763870716095\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 921: Train Loss: 0.13242985308170319, Val Loss: 0.11962634325027466\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 922: Train Loss: 0.1269286721944809, Val Loss: 0.1188242956995964\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 923: Train Loss: 0.12305707484483719, Val Loss: 0.11226793378591537\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 924: Train Loss: 0.11788692325353622, Val Loss: 0.10596469044685364\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 925: Train Loss: 0.11296876519918442, Val Loss: 0.09978251904249191\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 926: Train Loss: 0.10932771116495132, Val Loss: 0.09916843473911285\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 927: Train Loss: 0.1040952131152153, Val Loss: 0.09351808577775955\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 928: Train Loss: 0.09847038984298706, Val Loss: 0.08650221675634384\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 929: Train Loss: 0.09403383731842041, Val Loss: 0.08422457426786423\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 930: Train Loss: 0.09129593521356583, Val Loss: 0.08102451264858246\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 931: Train Loss: 0.08750870078802109, Val Loss: 0.07787174731492996\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 932: Train Loss: 0.08302412182092667, Val Loss: 0.07319942861795425\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 933: Train Loss: 0.07933178544044495, Val Loss: 0.06731375306844711\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 934: Train Loss: 0.07622448354959488, Val Loss: 0.0694219172000885\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 935: Train Loss: 0.07148682326078415, Val Loss: 0.0633254200220108\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 936: Train Loss: 0.06892219930887222, Val Loss: 0.06210728734731674\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 937: Train Loss: 0.06509922444820404, Val Loss: 0.05791429430246353\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 938: Train Loss: 0.06173711270093918, Val Loss: 0.05590149015188217\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 939: Train Loss: 0.059306591749191284, Val Loss: 0.04894010350108147\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 940: Train Loss: 0.05746065452694893, Val Loss: 0.049467042088508606\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 941: Train Loss: 0.054169826209545135, Val Loss: 0.0475376695394516\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 942: Train Loss: 0.05229779705405235, Val Loss: 0.04387349262833595\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 943: Train Loss: 0.04801861569285393, Val Loss: 0.041622649878263474\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 944: Train Loss: 0.047084957361221313, Val Loss: 0.041092172265052795\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 945: Train Loss: 0.04591863974928856, Val Loss: 0.037487491965293884\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 946: Train Loss: 0.04342157021164894, Val Loss: 0.03736079856753349\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 947: Train Loss: 0.08459000289440155, Val Loss: 0.040985897183418274\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 948: Train Loss: 0.046585146337747574, Val Loss: 0.04533134400844574\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 949: Train Loss: 0.05329924076795578, Val Loss: 0.05353206768631935\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 950: Train Loss: 0.05646239221096039, Val Loss: 0.05557001009583473\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 951: Train Loss: 0.06314348429441452, Val Loss: 0.060544535517692566\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 952: Train Loss: 0.06590493768453598, Val Loss: 0.06516236811876297\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 953: Train Loss: 0.0693015530705452, Val Loss: 0.06538204103708267\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 954: Train Loss: 0.07324516028165817, Val Loss: 0.07105552405118942\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 955: Train Loss: 0.07533734291791916, Val Loss: 0.07194238901138306\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 956: Train Loss: 0.07698355615139008, Val Loss: 0.07191579043865204\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 957: Train Loss: 0.0786268562078476, Val Loss: 0.07279737293720245\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 958: Train Loss: 0.0791812315583229, Val Loss: 0.07458378374576569\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 959: Train Loss: 0.08127036690711975, Val Loss: 0.0729258581995964\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 960: Train Loss: 0.08196106553077698, Val Loss: 0.07472416013479233\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 961: Train Loss: 0.08101904392242432, Val Loss: 0.07568284869194031\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 962: Train Loss: 0.07953335344791412, Val Loss: 0.07479239255189896\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 963: Train Loss: 0.08104363083839417, Val Loss: 0.07658138871192932\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 964: Train Loss: 0.07853418588638306, Val Loss: 0.07275187969207764\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 965: Train Loss: 0.07834378629922867, Val Loss: 0.0733598917722702\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 966: Train Loss: 0.07731757313013077, Val Loss: 0.07167357951402664\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 967: Train Loss: 0.07500465214252472, Val Loss: 0.06607037037611008\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 968: Train Loss: 0.07330916821956635, Val Loss: 0.06768448650836945\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 969: Train Loss: 0.07337581366300583, Val Loss: 0.06461724638938904\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 970: Train Loss: 0.06992028653621674, Val Loss: 0.0634974017739296\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 971: Train Loss: 0.06937986612319946, Val Loss: 0.06104040518403053\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 972: Train Loss: 0.0671149343252182, Val Loss: 0.06153453141450882\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 973: Train Loss: 0.06483069062232971, Val Loss: 0.059666749089956284\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 974: Train Loss: 0.06378202140331268, Val Loss: 0.057238269597291946\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 975: Train Loss: 0.062206462025642395, Val Loss: 0.054650723934173584\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 976: Train Loss: 0.05972479283809662, Val Loss: 0.05111819878220558\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 977: Train Loss: 0.057627756148576736, Val Loss: 0.05172388255596161\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 978: Train Loss: 0.057109296321868896, Val Loss: 0.05013131722807884\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 979: Train Loss: 0.05565100163221359, Val Loss: 0.045938704162836075\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 980: Train Loss: 0.052944622933864594, Val Loss: 0.04717054218053818\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 981: Train Loss: 0.050626419484615326, Val Loss: 0.046490609645843506\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 982: Train Loss: 0.04975020885467529, Val Loss: 0.04595164954662323\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 983: Train Loss: 0.04820077866315842, Val Loss: 0.04248722642660141\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 984: Train Loss: 0.046570733189582825, Val Loss: 0.04026630520820618\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 985: Train Loss: 0.04627949744462967, Val Loss: 0.040854644030332565\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 986: Train Loss: 0.0428994745016098, Val Loss: 0.038150884211063385\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 987: Train Loss: 0.04342840611934662, Val Loss: 0.038623154163360596\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 988: Train Loss: 0.04097909852862358, Val Loss: 0.034997325390577316\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 989: Train Loss: 0.03973029926419258, Val Loss: 0.03704969584941864\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 990: Train Loss: 0.0392521396279335, Val Loss: 0.6192100048065186\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 991: Train Loss: 0.037577155977487564, Val Loss: 0.03232303261756897\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 992: Train Loss: 0.03663963824510574, Val Loss: 0.03242357075214386\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 993: Train Loss: 0.036111727356910706, Val Loss: 0.029756449162960052\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 994: Train Loss: 0.03435199335217476, Val Loss: 0.029497668147087097\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 995: Train Loss: 0.033373355865478516, Val Loss: 0.02780120261013508\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 996: Train Loss: 0.03335040062665939, Val Loss: 0.028697114437818527\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 997: Train Loss: 0.031129775568842888, Val Loss: 0.02689005248248577\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 998: Train Loss: 0.030290797352790833, Val Loss: 0.025523457676172256\n",
      "Using Local Control.\n",
      "Using Local Control.\n",
      "Epoch 999: Train Loss: 0.029305947944521904, Val Loss: 0.026056407019495964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeff\\AppData\\Local\\Temp\\ipykernel_30828\\1290655766.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gnn.load_state_dict(torch.load('best_gnn_model.pth'))\n",
      "C:\\Users\\Jeff\\AppData\\Local\\Temp\\ipykernel_30828\\1290655766.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  policy_network.load_state_dict(torch.load('best_policy_network.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE New Training Method\n",
    "gnn_out_chann = 4 # Num of features out\n",
    "rl_out_channels = 4 # Controlling valve positions (one output per node)\n",
    "hidden_channels = 128\n",
    "gnn = GCN(in_channels=gnn_in_chan, hidden_channels=hidden_channels, out_channels=gnn_out_chann).to(device)\n",
    "policy_network = PolicyNetwork(input_dim=gnn_out_chann, output_dim=rl_out_channels).to(device)\n",
    "optimizer = torch.optim.Adam(list(gnn.parameters()) + list(policy_network.parameters()), lr=1e-3)\n",
    "# schedule = ReduceLROnPlateau\n",
    "\n",
    "num_episodes = 1_000\n",
    "best_loss = float(\"inf\")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "es_threshold = 15\n",
    "early_stoppping = 0\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True) # Inplace Error??\n",
    "for episode in range(num_episodes):\n",
    "    gnn.train()\n",
    "    policy_network.train()\n",
    "    \n",
    "    # Training Phase\n",
    "    train_current_water_levels = train_data.x[:, 0]\n",
    "    train_global_threshold = torch.quantile(train_current_water_levels, 0.95)\n",
    "    \n",
    "    node_representations = gnn(train_data)\n",
    "    actions = hybrid_control(node_representations, policy_network, train_global_threshold, train_current_water_levels)\n",
    "    new_state, reward = environment_step(node_representations, actions, train_data.edge_index, flow_capacities)\n",
    "    \n",
    "    train_loss = -reward.mean()\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses.append(train_loss.item())\n",
    "    \n",
    "    # Validation Phase\n",
    "    gnn.eval()\n",
    "    policy_network.eval()\n",
    "    with torch.no_grad():\n",
    "        val_node_representations = gnn(val_data)\n",
    "        val_actions = hybrid_control(val_node_representations, policy_network, train_global_threshold, val_data.x[:, 0])\n",
    "        val_new_state, val_reward = environment_step(val_node_representations, val_actions, val_data.edge_index, flow_capacities)        \n",
    "        val_loss = -val_reward.mean()\n",
    "        val_losses.append(val_loss.item())\n",
    "        \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping = 0 # Reset\n",
    "        torch.save(gnn.state_dict(), 'best_gnn_model.pth')\n",
    "        torch.save(policy_network.state_dict(), 'best_policy_network.pth')    \n",
    "    elif val_loss > best_loss:\n",
    "        early_stoppping += 1\n",
    "        if early_stoppping == es_threshold:\n",
    "            print(f'Early Stopping Triggered: Epoch {episode} | Train Loss: {train_loss.item()} | Val Loss: {val_loss.item()}')\n",
    "            break\n",
    "    print(f'Epoch {episode}: Train Loss: {train_loss.item()}, Val Loss: {val_loss.item()}')\n",
    "\n",
    "gnn.load_state_dict(torch.load('best_gnn_model.pth'))\n",
    "policy_network.load_state_dict(torch.load('best_policy_network.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precent Decreased by: 92.716%\n"
     ]
    }
   ],
   "source": [
    "percent_decreased = ((0.026056407019495964 - 0.3577325642108917) / 0.35773256421) * 100\n",
    "print(f\"Precent Decreased by: {abs(percent_decreased):.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching to Global Control!\n",
      "Episode 0: Loss = 7.6443891525268555\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 1: Loss = 5.821844100952148\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 2: Loss = 3.167064666748047\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 3: Loss = 0.8118022680282593\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 4: Loss = 0.8472369313240051\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 5: Loss = 0.8325866460800171\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 6: Loss = 0.860472559928894\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 7: Loss = 0.8724663853645325\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 8: Loss = 0.856708288192749\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 9: Loss = 0.8630848526954651\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 10: Loss = 0.8547080755233765\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 11: Loss = 0.8498978018760681\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 12: Loss = 0.838271975517273\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 13: Loss = 0.8246485590934753\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 14: Loss = 0.8023993968963623\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 15: Loss = 4.066475868225098\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 16: Loss = 0.8109148740768433\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 17: Loss = 0.779465913772583\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 18: Loss = 0.7989426255226135\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 19: Loss = 0.7826709747314453\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 20: Loss = 0.7861442565917969\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 21: Loss = 0.7730323672294617\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 22: Loss = 0.7692282199859619\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 23: Loss = 0.7654737830162048\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 24: Loss = 0.7509942650794983\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 25: Loss = 0.7490809559822083\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 26: Loss = 1.8018784523010254\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 27: Loss = 3.9625141620635986\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 28: Loss = 0.7374511361122131\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 29: Loss = 0.7647159695625305\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 30: Loss = 0.7740185260772705\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 31: Loss = 0.776820957660675\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 32: Loss = 0.8013594746589661\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 33: Loss = 0.7935633659362793\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 34: Loss = 0.8045772314071655\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 35: Loss = 0.8001962900161743\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 36: Loss = 0.7975884675979614\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 37: Loss = 0.8100483417510986\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 38: Loss = 0.8084396123886108\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 39: Loss = 0.8258406519889832\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 40: Loss = 0.806294858455658\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 41: Loss = 0.7908827662467957\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 42: Loss = 0.805141270160675\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 43: Loss = 0.8041999340057373\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 44: Loss = 0.781932532787323\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 45: Loss = 0.8034428954124451\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 46: Loss = 0.7883152365684509\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 47: Loss = 0.786422073841095\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 48: Loss = 0.7718998789787292\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 49: Loss = 1.863769769668579\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 50: Loss = 0.7602285742759705\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 51: Loss = 1.7314043045043945\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 52: Loss = 0.7679849863052368\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 53: Loss = 0.7402136325836182\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 54: Loss = 0.7640942931175232\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 55: Loss = 0.7540098428726196\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 56: Loss = 0.7509114146232605\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 57: Loss = 0.7392440438270569\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 58: Loss = 0.7570149302482605\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 59: Loss = 0.7528387308120728\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 60: Loss = 0.7385271787643433\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 61: Loss = 3.0409977436065674\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 62: Loss = 0.7594324946403503\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 63: Loss = 0.757249116897583\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 64: Loss = 0.7632940411567688\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 65: Loss = 0.7756348848342896\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 66: Loss = 0.7625958323478699\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 67: Loss = 0.7926228046417236\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 68: Loss = 0.7784965634346008\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 69: Loss = 0.7906768918037415\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 70: Loss = 0.794990599155426\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 71: Loss = 0.7918631434440613\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 72: Loss = 0.79755699634552\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 73: Loss = 0.7840778827667236\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 74: Loss = 0.7697178721427917\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 75: Loss = 0.7649433016777039\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 76: Loss = 0.7906891703605652\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 77: Loss = 0.7710637450218201\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 78: Loss = 0.7614765763282776\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 79: Loss = 0.759834349155426\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 80: Loss = 0.7550533413887024\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 81: Loss = 0.7407244443893433\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 82: Loss = 0.7299864292144775\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 83: Loss = 0.7418234348297119\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 84: Loss = 0.727168083190918\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 85: Loss = 0.7115435600280762\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 86: Loss = 0.6979627013206482\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 87: Loss = 0.6735511422157288\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 88: Loss = 2.790731430053711\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 89: Loss = 0.6649985909461975\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 90: Loss = 0.6738343834877014\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 91: Loss = 0.685310959815979\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 92: Loss = 0.6894001364707947\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 93: Loss = 0.6802128553390503\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 94: Loss = 0.6844369173049927\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 95: Loss = 0.6753842234611511\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 96: Loss = 0.6684756278991699\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 97: Loss = 0.6862433552742004\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 98: Loss = 0.6847680807113647\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 99: Loss = 0.6676447987556458\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 100: Loss = 0.6514183878898621\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 101: Loss = 0.6277490258216858\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 102: Loss = 0.6172341108322144\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 103: Loss = 0.6087396740913391\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 104: Loss = 5.280714988708496\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 105: Loss = 3.7809665203094482\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 106: Loss = 0.6369032263755798\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 107: Loss = 0.6383439302444458\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 108: Loss = 0.690455436706543\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 109: Loss = 0.7269701957702637\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 110: Loss = 0.7228678464889526\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 111: Loss = 0.7385368347167969\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 112: Loss = 0.7418491244316101\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 113: Loss = 0.7496095895767212\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 114: Loss = 0.7647277116775513\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 115: Loss = 0.7636482119560242\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 116: Loss = 0.7560998201370239\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 117: Loss = 0.7720562815666199\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 118: Loss = 0.767315149307251\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 119: Loss = 0.744918942451477\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 120: Loss = 0.7500408887863159\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 121: Loss = 0.7663024067878723\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 122: Loss = 0.7482423186302185\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 123: Loss = 0.7383369207382202\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 124: Loss = 0.7358943223953247\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 125: Loss = 0.7373101115226746\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 126: Loss = 0.7123764157295227\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 127: Loss = 0.7232991456985474\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 128: Loss = 0.7056741118431091\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 129: Loss = 0.7012210488319397\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 130: Loss = 0.6665847897529602\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 131: Loss = 0.6477749347686768\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 132: Loss = 0.6377633810043335\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 133: Loss = 4.197079181671143\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 134: Loss = 3.189462661743164\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 135: Loss = 0.6724534630775452\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 136: Loss = 0.6957165598869324\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 137: Loss = 0.712308943271637\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 138: Loss = 0.7414807081222534\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 139: Loss = 0.7543812394142151\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 140: Loss = 0.7737089395523071\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 141: Loss = 0.7863336205482483\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 142: Loss = 0.7832449078559875\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 143: Loss = 0.7940965294837952\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 144: Loss = 0.7925689816474915\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 145: Loss = 0.7865802645683289\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 146: Loss = 0.8128412365913391\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 147: Loss = 0.786687970161438\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 148: Loss = 0.8029764890670776\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 149: Loss = 0.8089540004730225\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 150: Loss = 0.7827896475791931\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 151: Loss = 0.7961446046829224\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 152: Loss = 0.7770493626594543\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 153: Loss = 0.7765533328056335\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 154: Loss = 0.7948933243751526\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 155: Loss = 0.777341902256012\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 156: Loss = 0.7907395958900452\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 157: Loss = 0.768850564956665\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 158: Loss = 0.7686639428138733\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 159: Loss = 0.7655048966407776\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 160: Loss = 0.7528798580169678\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 161: Loss = 0.7572234272956848\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 162: Loss = 0.7604582905769348\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 163: Loss = 0.7549778819084167\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 164: Loss = 0.7471204996109009\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 165: Loss = 0.7670689225196838\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 166: Loss = 0.7379549741744995\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 167: Loss = 0.7383232116699219\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 168: Loss = 0.7521479725837708\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 169: Loss = 0.7579118013381958\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 170: Loss = 0.7633393406867981\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 171: Loss = 0.764286458492279\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 172: Loss = 0.7832239866256714\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 173: Loss = 0.7698310613632202\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 174: Loss = 0.7702706456184387\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 175: Loss = 0.7619293928146362\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 176: Loss = 0.7678340077400208\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 177: Loss = 0.7547696232795715\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 178: Loss = 0.7685514688491821\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 179: Loss = 0.7559946179389954\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 180: Loss = 0.752121090888977\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 181: Loss = 0.7617694735527039\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 182: Loss = 0.7292581796646118\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 183: Loss = 0.7467162013053894\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 184: Loss = 0.7380823493003845\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 185: Loss = 0.7246181964874268\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 186: Loss = 0.7191960215568542\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 187: Loss = 0.7126171588897705\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 188: Loss = 0.7119343280792236\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 189: Loss = 0.6840022206306458\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 190: Loss = 0.6903766989707947\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 191: Loss = 0.6630964279174805\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 192: Loss = 0.6727612018585205\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 193: Loss = 0.6655824184417725\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 194: Loss = 0.6301187872886658\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 195: Loss = 0.6253024339675903\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 196: Loss = 0.6266384124755859\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 197: Loss = 0.5939778685569763\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 198: Loss = 0.5939552783966064\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 199: Loss = 0.5642867684364319\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 200: Loss = 5.530912399291992\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 201: Loss = 0.5900397300720215\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 202: Loss = 0.5761111974716187\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 203: Loss = 0.604817807674408\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 204: Loss = 0.6238434314727783\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 205: Loss = 0.61365807056427\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 206: Loss = 0.6222811937332153\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 207: Loss = 0.6196779012680054\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 208: Loss = 0.6145158410072327\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 209: Loss = 0.6020153164863586\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 210: Loss = 0.6117140650749207\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 211: Loss = 0.6198237538337708\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 212: Loss = 0.5922168493270874\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 213: Loss = 0.6022449731826782\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 214: Loss = 0.5992663502693176\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 215: Loss = 0.6043444871902466\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 216: Loss = 0.570563018321991\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 217: Loss = 0.5801524519920349\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 218: Loss = 0.5609245300292969\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 219: Loss = 0.5415504574775696\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 220: Loss = 0.5262648463249207\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 221: Loss = 0.5331684947013855\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 222: Loss = 0.9909760355949402\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 223: Loss = 0.5262202620506287\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 224: Loss = 0.5339579582214355\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 225: Loss = 0.5311508774757385\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 226: Loss = 0.5406913757324219\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 227: Loss = 0.5427817702293396\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 228: Loss = 0.5234985947608948\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 229: Loss = 0.5113632678985596\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 230: Loss = 0.5383788347244263\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 231: Loss = 0.5071491003036499\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 232: Loss = 0.5034790635108948\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 233: Loss = 0.4957023561000824\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 234: Loss = 0.5105445384979248\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 235: Loss = 0.510188639163971\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 236: Loss = 1.7390353679656982\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 237: Loss = 0.48770812153816223\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 238: Loss = 0.5205415487289429\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 239: Loss = 0.9468700289726257\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 240: Loss = 0.5158430933952332\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 241: Loss = 0.5522019863128662\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 242: Loss = 0.5765652060508728\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 243: Loss = 0.606310248374939\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 244: Loss = 0.6248374581336975\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 245: Loss = 0.6008270978927612\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 246: Loss = 0.611033022403717\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 247: Loss = 0.6204260587692261\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 248: Loss = 0.6258412003517151\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 249: Loss = 0.6086744666099548\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 250: Loss = 0.6253599524497986\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 251: Loss = 0.6288078427314758\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 252: Loss = 0.6268960237503052\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 253: Loss = 0.618450939655304\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 254: Loss = 0.6238923668861389\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 255: Loss = 0.5881487727165222\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 256: Loss = 0.5914397239685059\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 257: Loss = 0.6001535654067993\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 258: Loss = 0.5572424530982971\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 259: Loss = 0.569158673286438\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 260: Loss = 0.5655600428581238\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 261: Loss = 0.5472084879875183\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 262: Loss = 0.5387247204780579\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 263: Loss = 0.527441143989563\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 264: Loss = 0.5179267525672913\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 265: Loss = 0.497832715511322\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 266: Loss = 0.4809857904911041\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 267: Loss = 0.49804258346557617\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 268: Loss = 0.472370445728302\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 269: Loss = 0.458679735660553\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 270: Loss = 0.4452807605266571\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 271: Loss = 2.089643955230713\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 272: Loss = 1.11216402053833\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 273: Loss = 0.4482896327972412\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 274: Loss = 0.43610572814941406\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 275: Loss = 0.47348013520240784\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 276: Loss = 0.47172918915748596\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 277: Loss = 0.4942528307437897\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 278: Loss = 0.497587114572525\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 279: Loss = 0.46922990679740906\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 280: Loss = 0.48998183012008667\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 281: Loss = 0.5133256912231445\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 282: Loss = 1.5809333324432373\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 283: Loss = 0.9149443507194519\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 284: Loss = 0.5743250250816345\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 285: Loss = 0.581821858882904\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 286: Loss = 0.6110988259315491\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 287: Loss = 0.6332531571388245\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 288: Loss = 0.6481338143348694\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 289: Loss = 0.6660914421081543\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 290: Loss = 0.6793352365493774\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 291: Loss = 0.6906365752220154\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 292: Loss = 0.6923540830612183\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 293: Loss = 0.7035422921180725\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 294: Loss = 0.7085139155387878\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 295: Loss = 0.6913856267929077\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 296: Loss = 0.7150930762290955\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 297: Loss = 0.7213636636734009\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 298: Loss = 0.6966010928153992\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 299: Loss = 0.7142508029937744\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 300: Loss = 0.7163673043251038\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 301: Loss = 0.7067254185676575\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 302: Loss = 0.7041515707969666\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 303: Loss = 0.7139768600463867\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 304: Loss = 0.7016901969909668\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 305: Loss = 0.7048784494400024\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 306: Loss = 0.6889501214027405\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 307: Loss = 0.6974621415138245\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 308: Loss = 0.6945798397064209\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 309: Loss = 0.683826208114624\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 310: Loss = 1.5651099681854248\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 311: Loss = 0.7053951025009155\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 312: Loss = 0.7183549404144287\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 313: Loss = 0.7328219413757324\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 314: Loss = 0.715404212474823\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 315: Loss = 0.7290781736373901\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 316: Loss = 0.7129456996917725\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 317: Loss = 0.7313485741615295\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 318: Loss = 0.7311112284660339\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 319: Loss = 0.7443384528160095\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 320: Loss = 0.737702488899231\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 321: Loss = 0.739055871963501\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 322: Loss = 0.733568549156189\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 323: Loss = 0.7428427934646606\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 324: Loss = 0.7376133799552917\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 325: Loss = 0.7279478311538696\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 326: Loss = 0.7409760355949402\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 327: Loss = 0.738775908946991\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 328: Loss = 0.7395485639572144\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 329: Loss = 0.7234132289886475\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 330: Loss = 0.7250356674194336\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 331: Loss = 0.7279303073883057\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 332: Loss = 0.7271255254745483\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 333: Loss = 0.7154028415679932\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 334: Loss = 0.7162351012229919\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 335: Loss = 0.6940687298774719\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 336: Loss = 0.7101168632507324\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 337: Loss = 0.6972378492355347\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 338: Loss = 0.707783043384552\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 339: Loss = 0.70132976770401\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 340: Loss = 0.6837926506996155\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 341: Loss = 0.6874740719795227\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 342: Loss = 0.6834423542022705\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 343: Loss = 0.6708678007125854\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 344: Loss = 0.674292266368866\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 345: Loss = 0.6870140433311462\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 346: Loss = 0.6668829917907715\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 347: Loss = 0.6472587585449219\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 348: Loss = 0.6420073509216309\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 349: Loss = 0.6336061954498291\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 350: Loss = 0.6556919813156128\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 351: Loss = 0.6287586092948914\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 352: Loss = 0.6393225193023682\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 353: Loss = 0.6198159456253052\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 354: Loss = 0.6221477389335632\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 355: Loss = 0.601254940032959\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 356: Loss = 0.6062971949577332\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 357: Loss = 0.5969157218933105\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 358: Loss = 0.5941126346588135\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 359: Loss = 0.5883171558380127\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 360: Loss = 0.59224534034729\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 361: Loss = 0.5708417892456055\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 362: Loss = 0.5610392093658447\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 363: Loss = 0.5567256808280945\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 364: Loss = 0.5700778961181641\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 365: Loss = 0.551524817943573\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 366: Loss = 0.5522737503051758\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 367: Loss = 0.556506872177124\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 368: Loss = 0.538804292678833\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 369: Loss = 0.5213948488235474\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 370: Loss = 0.5388398766517639\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 371: Loss = 0.5191380977630615\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 372: Loss = 0.5042017102241516\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 373: Loss = 0.5128177404403687\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 374: Loss = 0.5145902633666992\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 375: Loss = 0.5021668076515198\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 376: Loss = 0.49204254150390625\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 377: Loss = 0.4995429515838623\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 378: Loss = 0.47129520773887634\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 379: Loss = 0.4749862551689148\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 380: Loss = 0.4813135862350464\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 381: Loss = 0.47109755873680115\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 382: Loss = 0.47372138500213623\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 383: Loss = 0.4599311649799347\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 384: Loss = 0.4345255494117737\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 385: Loss = 0.44590049982070923\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 386: Loss = 1.894912838935852\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 387: Loss = 0.43798303604125977\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 388: Loss = 0.4609963893890381\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 389: Loss = 0.45975470542907715\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 390: Loss = 0.4500080645084381\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 391: Loss = 0.4661542475223541\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 392: Loss = 0.5076674222946167\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 393: Loss = 0.46379610896110535\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 394: Loss = 0.48419755697250366\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 395: Loss = 0.5098742842674255\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 396: Loss = 0.5022024512290955\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 397: Loss = 0.5195136070251465\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 398: Loss = 0.511602520942688\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 399: Loss = 0.5493807196617126\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 400: Loss = 0.5341306924819946\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 401: Loss = 0.5331343412399292\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 402: Loss = 0.5318300724029541\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 403: Loss = 0.5328342914581299\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 404: Loss = 0.5205327868461609\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 405: Loss = 0.5155499577522278\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 406: Loss = 0.5444208979606628\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 407: Loss = 0.5200695395469666\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 408: Loss = 0.5213931798934937\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 409: Loss = 0.51857590675354\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 410: Loss = 0.522685706615448\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 411: Loss = 0.5129547119140625\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 412: Loss = 0.5162498950958252\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 413: Loss = 0.5018836855888367\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 414: Loss = 0.5226927995681763\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 415: Loss = 0.5234736800193787\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 416: Loss = 0.4996646046638489\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 417: Loss = 0.4831427037715912\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 418: Loss = 0.4956671893596649\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 419: Loss = 0.4887927770614624\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 420: Loss = 0.47664618492126465\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 421: Loss = 0.4867931306362152\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 422: Loss = 0.4858649671077728\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 423: Loss = 0.47952574491500854\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 424: Loss = 0.46552222967147827\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 425: Loss = 0.4598202407360077\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 426: Loss = 0.4660096764564514\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 427: Loss = 0.5559519529342651\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 428: Loss = 0.44421783089637756\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 429: Loss = 0.4541763663291931\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 430: Loss = 0.46650415658950806\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 431: Loss = 0.45930275321006775\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 432: Loss = 0.4603668749332428\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 433: Loss = 0.4654256999492645\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 434: Loss = 0.4675586521625519\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 435: Loss = 0.482583612203598\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 436: Loss = 0.458281546831131\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 437: Loss = 0.475246787071228\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 438: Loss = 0.4621953070163727\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 439: Loss = 0.45711708068847656\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 440: Loss = 0.4610022008419037\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 441: Loss = 0.45173677802085876\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 442: Loss = 0.45244085788726807\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 443: Loss = 0.43762198090553284\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 444: Loss = 0.43928512930870056\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 445: Loss = 0.44899824261665344\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 446: Loss = 0.4340600371360779\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 447: Loss = 0.4245298206806183\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 448: Loss = 0.4337380528450012\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 449: Loss = 0.41343954205513\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 450: Loss = 0.43648025393486023\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 451: Loss = 0.453011691570282\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 452: Loss = 0.4459427297115326\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 453: Loss = 0.44321027398109436\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 454: Loss = 0.43402788043022156\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 455: Loss = 0.4384947419166565\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 456: Loss = 0.44008150696754456\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 457: Loss = 0.45543035864830017\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 458: Loss = 0.4670698940753937\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 459: Loss = 0.46022361516952515\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 460: Loss = 0.4683769941329956\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 461: Loss = 0.46225839853286743\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 462: Loss = 0.4658176004886627\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 463: Loss = 0.48385655879974365\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 464: Loss = 0.4733531177043915\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 465: Loss = 0.46990278363227844\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 466: Loss = 0.4619746208190918\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 467: Loss = 0.45279189944267273\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 468: Loss = 0.4554671347141266\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 469: Loss = 0.4602378010749817\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 470: Loss = 0.4554003179073334\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 471: Loss = 0.44607093930244446\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 472: Loss = 0.4571881890296936\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 473: Loss = 0.4463200271129608\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 474: Loss = 0.4397270083427429\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 475: Loss = 0.448537677526474\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 476: Loss = 0.4563107192516327\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 477: Loss = 0.42174917459487915\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 478: Loss = 0.4275401830673218\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 479: Loss = 0.4213063716888428\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 480: Loss = 0.41797569394111633\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 481: Loss = 0.43440353870391846\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 482: Loss = 0.4200175702571869\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 483: Loss = 0.4094074070453644\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 484: Loss = 0.41191238164901733\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 485: Loss = 0.41358062624931335\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 486: Loss = 0.4062603712081909\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 487: Loss = 0.41464439034461975\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 488: Loss = 0.5500441789627075\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 489: Loss = 1.1386077404022217\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 490: Loss = 0.4264076054096222\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 491: Loss = 0.4475250244140625\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 492: Loss = 0.4511055648326874\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 493: Loss = 0.4339083433151245\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 494: Loss = 0.44500622153282166\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 495: Loss = 0.49682241678237915\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 496: Loss = 0.4672616720199585\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 497: Loss = 0.485187292098999\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 498: Loss = 0.4936876893043518\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 499: Loss = 0.4886407256126404\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 500: Loss = 0.4977179169654846\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 501: Loss = 0.48462575674057007\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 502: Loss = 0.4940563142299652\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 503: Loss = 0.503591001033783\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 504: Loss = 0.49529966711997986\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 505: Loss = 0.5157344937324524\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 506: Loss = 0.5052129030227661\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 507: Loss = 0.4994206130504608\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 508: Loss = 0.48736265301704407\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 509: Loss = 0.5032572150230408\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 510: Loss = 0.47179725766181946\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 511: Loss = 0.497841477394104\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 512: Loss = 0.48822256922721863\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 513: Loss = 0.48650142550468445\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 514: Loss = 0.45715299248695374\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 515: Loss = 0.4641402065753937\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 516: Loss = 0.4817911684513092\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 517: Loss = 0.47611692547798157\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 518: Loss = 0.45917463302612305\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 519: Loss = 0.4638335406780243\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 520: Loss = 0.44725340604782104\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 521: Loss = 0.4341760575771332\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 522: Loss = 0.42941364645957947\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 523: Loss = 0.434946209192276\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 524: Loss = 0.4370478093624115\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 525: Loss = 0.4304245710372925\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 526: Loss = 0.41329002380371094\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 527: Loss = 0.43239936232566833\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 528: Loss = 0.4323481023311615\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 529: Loss = 0.4232177734375\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 530: Loss = 0.42020872235298157\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 531: Loss = 0.40973562002182007\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 532: Loss = 0.4095354378223419\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 533: Loss = 0.3996141850948334\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 534: Loss = 0.3843717873096466\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 535: Loss = 0.38559630513191223\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 536: Loss = 0.3847404420375824\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 537: Loss = 1.5732558965682983\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 538: Loss = 0.40904080867767334\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 539: Loss = 0.39775678515434265\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 540: Loss = 0.41433700919151306\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 541: Loss = 0.41324132680892944\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 542: Loss = 0.41386815905570984\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 543: Loss = 0.4313161373138428\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 544: Loss = 0.4130586087703705\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 545: Loss = 0.41073065996170044\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 546: Loss = 0.426511287689209\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 547: Loss = 0.4432334899902344\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 548: Loss = 0.4382144808769226\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 549: Loss = 0.42908063530921936\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 550: Loss = 0.43886706233024597\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 551: Loss = 0.41544437408447266\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 552: Loss = 0.430338054895401\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 553: Loss = 0.425737589597702\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 554: Loss = 0.43759191036224365\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 555: Loss = 0.4337713122367859\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 556: Loss = 0.44188612699508667\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 557: Loss = 0.42980116605758667\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 558: Loss = 0.40505293011665344\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 559: Loss = 0.412972629070282\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 560: Loss = 0.4194072484970093\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 561: Loss = 0.4127693474292755\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 562: Loss = 0.4050614833831787\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 563: Loss = 0.4041929841041565\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 564: Loss = 0.4026382863521576\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 565: Loss = 0.39847487211227417\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 566: Loss = 0.39593178033828735\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 567: Loss = 0.47019633650779724\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 568: Loss = 0.39205101132392883\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 569: Loss = 0.402885377407074\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 570: Loss = 0.3912663161754608\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 571: Loss = 0.4030805826187134\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 572: Loss = 0.4110602140426636\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 573: Loss = 0.4009094834327698\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 574: Loss = 0.43217307329177856\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 575: Loss = 0.41356077790260315\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 576: Loss = 0.41952887177467346\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 577: Loss = 0.4184103012084961\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 578: Loss = 0.40627288818359375\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 579: Loss = 0.47949787974357605\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 580: Loss = 0.4148612916469574\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 581: Loss = 0.4234681725502014\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 582: Loss = 0.44729989767074585\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 583: Loss = 0.45831888914108276\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 584: Loss = 0.4507206380367279\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 585: Loss = 0.45731958746910095\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 586: Loss = 0.4689100682735443\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 587: Loss = 0.4631880223751068\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 588: Loss = 0.4670533239841461\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 589: Loss = 0.4709181487560272\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 590: Loss = 0.47953689098358154\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 591: Loss = 0.48986074328422546\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 592: Loss = 0.46708694100379944\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 593: Loss = 0.48121824860572815\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 594: Loss = 0.4758077561855316\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 595: Loss = 0.49808409810066223\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 596: Loss = 4.27882719039917\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 597: Loss = 0.4982834458351135\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 598: Loss = 0.5132645964622498\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 599: Loss = 0.5352717638015747\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 600: Loss = 0.5394447445869446\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 601: Loss = 0.5637792944908142\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 602: Loss = 0.5670008063316345\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 603: Loss = 0.5831125378608704\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 604: Loss = 0.5785230994224548\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 605: Loss = 0.5955516695976257\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 606: Loss = 0.6047145128250122\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 607: Loss = 0.6029664278030396\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 608: Loss = 0.6159807443618774\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 609: Loss = 0.6366685628890991\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 610: Loss = 0.6165589094161987\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 611: Loss = 0.636979341506958\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 612: Loss = 0.6076684594154358\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 613: Loss = 0.6228261590003967\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 614: Loss = 0.6051769256591797\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 615: Loss = 0.6205267906188965\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 616: Loss = 0.6073464751243591\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 617: Loss = 0.6147940158843994\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 618: Loss = 0.6119216680526733\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 619: Loss = 0.6199024319648743\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 620: Loss = 0.5785177946090698\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 621: Loss = 0.5762616991996765\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 622: Loss = 0.6013522744178772\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 623: Loss = 0.5843073725700378\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 624: Loss = 0.5799633860588074\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 625: Loss = 0.5927284359931946\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 626: Loss = 0.5678123831748962\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 627: Loss = 0.576056957244873\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 628: Loss = 0.5616421103477478\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 629: Loss = 0.5511964559555054\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 630: Loss = 0.5584353804588318\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 631: Loss = 0.5307694673538208\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 632: Loss = 0.5388389229774475\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 633: Loss = 0.521785318851471\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 634: Loss = 0.5284095406532288\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 635: Loss = 0.5300208330154419\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 636: Loss = 0.5231882929801941\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 637: Loss = 0.5216607451438904\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 638: Loss = 0.5145970582962036\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 639: Loss = 0.5123123526573181\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 640: Loss = 0.49763381481170654\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 641: Loss = 0.5064281225204468\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 642: Loss = 0.5126345157623291\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 643: Loss = 0.4878978729248047\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 644: Loss = 0.48386240005493164\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 645: Loss = 0.4737670123577118\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 646: Loss = 0.47088977694511414\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 647: Loss = 0.4607463777065277\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 648: Loss = 0.46831464767456055\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 649: Loss = 0.4515370726585388\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 650: Loss = 0.4397645592689514\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 651: Loss = 0.431322306394577\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 652: Loss = 0.4505012333393097\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 653: Loss = 0.4321959912776947\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 654: Loss = 2.0801780223846436\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 655: Loss = 0.42879652976989746\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 656: Loss = 0.4402383267879486\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 657: Loss = 0.447988361120224\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 658: Loss = 0.4434082806110382\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 659: Loss = 0.4632267951965332\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 660: Loss = 0.4724422097206116\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 661: Loss = 0.47644057869911194\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 662: Loss = 0.4592796564102173\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 663: Loss = 0.4514351487159729\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 664: Loss = 0.4614414572715759\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 665: Loss = 0.46885573863983154\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 666: Loss = 0.4472653865814209\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 667: Loss = 0.47245898842811584\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 668: Loss = 0.46660467982292175\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 669: Loss = 0.4533396065235138\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 670: Loss = 0.4556584060192108\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 671: Loss = 0.4703652858734131\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 672: Loss = 0.4472763240337372\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 673: Loss = 0.44790634512901306\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 674: Loss = 0.4487052857875824\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 675: Loss = 0.43888649344444275\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 676: Loss = 0.4381285309791565\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 677: Loss = 0.4417642056941986\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 678: Loss = 0.4377579689025879\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 679: Loss = 0.4244554042816162\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 680: Loss = 0.4390583634376526\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 681: Loss = 0.4288487136363983\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 682: Loss = 0.42408287525177\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 683: Loss = 0.4056362509727478\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 684: Loss = 0.41405677795410156\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 685: Loss = 0.3958011567592621\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 686: Loss = 0.407206267118454\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 687: Loss = 0.40063443779945374\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 688: Loss = 0.38787057995796204\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 689: Loss = 0.3809889256954193\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 690: Loss = 0.3899633586406708\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 691: Loss = 0.39242568612098694\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 692: Loss = 0.38219672441482544\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 693: Loss = 0.3708481192588806\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 694: Loss = 0.3813152611255646\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 695: Loss = 0.4407504200935364\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 696: Loss = 0.3722831606864929\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 697: Loss = 0.37805065512657166\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 698: Loss = 0.3908225893974304\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 699: Loss = 0.8641980290412903\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 700: Loss = 0.3984282910823822\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 701: Loss = 0.40470966696739197\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 702: Loss = 5.415698528289795\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 703: Loss = 0.4385933578014374\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 704: Loss = 0.44931986927986145\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 705: Loss = 0.4814174473285675\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 706: Loss = 0.48562389612197876\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 707: Loss = 0.5112714171409607\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 708: Loss = 0.5200618505477905\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 709: Loss = 0.5226507186889648\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 710: Loss = 0.52711021900177\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 711: Loss = 0.5325095057487488\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 712: Loss = 0.5438348054885864\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 713: Loss = 0.53188556432724\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 714: Loss = 0.5521013140678406\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 715: Loss = 0.5459278225898743\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 716: Loss = 0.5519033074378967\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 717: Loss = 0.543870747089386\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 718: Loss = 0.5501212477684021\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 719: Loss = 0.5264576077461243\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 720: Loss = 0.5437808632850647\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 721: Loss = 0.5568417906761169\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 722: Loss = 0.5276437401771545\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 723: Loss = 0.5313655734062195\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 724: Loss = 0.5410144329071045\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 725: Loss = 0.5425893068313599\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 726: Loss = 0.5149537324905396\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 727: Loss = 0.5209172964096069\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 728: Loss = 0.523629903793335\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 729: Loss = 0.5277576446533203\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 730: Loss = 0.5174078345298767\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 731: Loss = 0.5221680998802185\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 732: Loss = 0.4943941533565521\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 733: Loss = 0.4942452907562256\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 734: Loss = 0.49225690960884094\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 735: Loss = 0.500404417514801\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 736: Loss = 0.49385225772857666\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 737: Loss = 0.48218944668769836\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 738: Loss = 0.4856998324394226\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 739: Loss = 0.48708146810531616\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 740: Loss = 0.47634437680244446\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 741: Loss = 0.4730847477912903\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 742: Loss = 0.4757579565048218\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 743: Loss = 0.4653581976890564\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 744: Loss = 0.4567066729068756\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 745: Loss = 0.45442909002304077\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 746: Loss = 0.45444002747535706\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 747: Loss = 0.4450790584087372\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 748: Loss = 0.44453147053718567\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 749: Loss = 0.43021711707115173\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 750: Loss = 0.4388085901737213\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 751: Loss = 0.42264524102211\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 752: Loss = 0.4185420274734497\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 753: Loss = 0.4330906569957733\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 754: Loss = 0.4093870520591736\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 755: Loss = 0.4188108742237091\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 756: Loss = 0.4024331271648407\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 757: Loss = 0.41001713275909424\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 758: Loss = 0.4090695083141327\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 759: Loss = 0.400145947933197\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 760: Loss = 0.3964916467666626\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 761: Loss = 0.39795348048210144\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 762: Loss = 0.38389238715171814\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 763: Loss = 1.0765600204467773\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 764: Loss = 0.40503355860710144\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 765: Loss = 0.3927189111709595\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 766: Loss = 0.4286664128303528\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 767: Loss = 0.4352557957172394\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 768: Loss = 0.4321077764034271\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 769: Loss = 0.4476776123046875\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 770: Loss = 0.4578890800476074\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 771: Loss = 0.4540344476699829\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 772: Loss = 0.4690381586551666\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 773: Loss = 0.4770139455795288\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 774: Loss = 0.47810378670692444\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 775: Loss = 0.4704746901988983\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 776: Loss = 0.4825511872768402\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 777: Loss = 0.47190597653388977\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 778: Loss = 0.48901137709617615\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 779: Loss = 0.47561851143836975\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 780: Loss = 0.5070734024047852\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 781: Loss = 0.4823315739631653\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 782: Loss = 0.48669856786727905\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 783: Loss = 0.480428546667099\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 784: Loss = 0.4880380928516388\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 785: Loss = 0.49370989203453064\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 786: Loss = 0.4698343873023987\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 787: Loss = 0.4962208569049835\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 788: Loss = 0.46168744564056396\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 789: Loss = 0.4670632779598236\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 790: Loss = 0.4738881587982178\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 791: Loss = 0.4734613597393036\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 792: Loss = 0.46363192796707153\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 793: Loss = 0.457373708486557\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 794: Loss = 0.45914512872695923\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 795: Loss = 0.4614560604095459\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 796: Loss = 0.45277777314186096\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 797: Loss = 0.45283830165863037\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 798: Loss = 0.4354265630245209\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 799: Loss = 0.4203592836856842\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 800: Loss = 0.43181487917900085\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 801: Loss = 0.42650672793388367\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 802: Loss = 0.42490580677986145\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 803: Loss = 0.42405638098716736\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 804: Loss = 0.4149785041809082\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 805: Loss = 0.4255436658859253\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 806: Loss = 0.40420374274253845\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 807: Loss = 0.40519213676452637\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 808: Loss = 0.40559354424476624\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 809: Loss = 0.4049617350101471\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 810: Loss = 0.709071695804596\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 811: Loss = 0.5310674905776978\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 812: Loss = 0.40824535489082336\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 813: Loss = 0.4323386251926422\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 814: Loss = 0.42822518944740295\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 815: Loss = 0.43269476294517517\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 816: Loss = 0.4459933340549469\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 817: Loss = 1.464287519454956\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 818: Loss = 0.4507804811000824\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 819: Loss = 0.46561649441719055\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 820: Loss = 0.4934590756893158\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 821: Loss = 0.4887695610523224\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 822: Loss = 0.5030292272567749\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 823: Loss = 0.5019584894180298\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 824: Loss = 0.5201470851898193\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 825: Loss = 0.5107942223548889\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 826: Loss = 0.5093485713005066\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 827: Loss = 0.5050907731056213\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 828: Loss = 0.5120177268981934\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 829: Loss = 0.5111751556396484\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 830: Loss = 0.5169600248336792\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 831: Loss = 0.5178576111793518\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 832: Loss = 0.5207565426826477\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 833: Loss = 0.512192964553833\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 834: Loss = 0.5075691938400269\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 835: Loss = 0.5038053393363953\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 836: Loss = 0.5141533017158508\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 837: Loss = 0.5040627717971802\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 838: Loss = 0.5077765583992004\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 839: Loss = 0.50871342420578\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 840: Loss = 0.497314453125\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 841: Loss = 0.48904871940612793\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 842: Loss = 0.48295828700065613\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 843: Loss = 0.48280802369117737\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 844: Loss = 0.47898611426353455\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 845: Loss = 0.4766780734062195\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 846: Loss = 0.471669465303421\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 847: Loss = 0.4567751884460449\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 848: Loss = 0.4604712426662445\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 849: Loss = 0.4584791958332062\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 850: Loss = 0.45338675379753113\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 851: Loss = 0.4299176037311554\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 852: Loss = 0.4454176127910614\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 853: Loss = 0.44609469175338745\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 854: Loss = 0.4409179985523224\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 855: Loss = 0.4373253583908081\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 856: Loss = 0.42097383737564087\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 857: Loss = 0.4228951930999756\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 858: Loss = 0.4032401442527771\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 859: Loss = 0.40149012207984924\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 860: Loss = 0.41158175468444824\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 861: Loss = 1.4543702602386475\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 862: Loss = 0.4046494960784912\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 863: Loss = 0.4187053143978119\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 864: Loss = 1.068117618560791\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 865: Loss = 0.442762166261673\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 866: Loss = 0.4609338641166687\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 867: Loss = 0.48659247159957886\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 868: Loss = 0.5028417706489563\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 869: Loss = 0.5171629190444946\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 870: Loss = 0.5355707406997681\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 871: Loss = 0.5435596704483032\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 872: Loss = 0.5429137945175171\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 873: Loss = 0.5556657314300537\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 874: Loss = 0.5707199573516846\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 875: Loss = 0.5657731294631958\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 876: Loss = 0.5900596976280212\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 877: Loss = 0.5799121260643005\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 878: Loss = 0.5874057412147522\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 879: Loss = 0.5918100476264954\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 880: Loss = 0.5864648818969727\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 881: Loss = 0.5884335041046143\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 882: Loss = 0.5805195569992065\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 883: Loss = 0.5862041115760803\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 884: Loss = 0.5759528279304504\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 885: Loss = 0.5814084410667419\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 886: Loss = 0.5721601843833923\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 887: Loss = 0.5840587615966797\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 888: Loss = 0.5780841112136841\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 889: Loss = 0.5752938985824585\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 890: Loss = 0.5987995862960815\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 891: Loss = 0.5739559531211853\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 892: Loss = 0.5661400556564331\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 893: Loss = 0.5602449774742126\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 894: Loss = 0.5551649332046509\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 895: Loss = 0.5624822378158569\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 896: Loss = 0.5542322993278503\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 897: Loss = 0.5505548715591431\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 898: Loss = 0.5468443036079407\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 899: Loss = 0.5326756834983826\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 900: Loss = 0.5281068682670593\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 901: Loss = 0.5345774292945862\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 902: Loss = 0.519085168838501\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 903: Loss = 0.517647385597229\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 904: Loss = 0.5164712071418762\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 905: Loss = 0.5190253257751465\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 906: Loss = 0.4944746196269989\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 907: Loss = 0.5109879374504089\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 908: Loss = 0.5130836367607117\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 909: Loss = 0.5128281116485596\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 910: Loss = 0.495471328496933\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 911: Loss = 0.4998253881931305\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 912: Loss = 0.4858378469944\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 913: Loss = 0.4822874069213867\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 914: Loss = 0.48188239336013794\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 915: Loss = 0.4769454598426819\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 916: Loss = 0.46233931183815\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 917: Loss = 0.4553965628147125\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 918: Loss = 0.4590977430343628\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 919: Loss = 0.4629538655281067\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 920: Loss = 0.4300867021083832\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 921: Loss = 0.44767868518829346\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 922: Loss = 0.44717735052108765\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 923: Loss = 0.4379909038543701\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 924: Loss = 0.4438689947128296\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 925: Loss = 0.4340962767601013\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 926: Loss = 0.42159897089004517\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 927: Loss = 0.42227309942245483\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 928: Loss = 0.4226743280887604\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 929: Loss = 0.43114981055259705\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 930: Loss = 0.4277481436729431\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 931: Loss = 0.40152257680892944\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 932: Loss = 0.40992262959480286\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 933: Loss = 0.4013139605522156\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 934: Loss = 0.4011306166648865\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 935: Loss = 0.4015398323535919\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 936: Loss = 0.39366328716278076\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 937: Loss = 1.741754174232483\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 938: Loss = 0.4059150516986847\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 939: Loss = 0.40277040004730225\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 940: Loss = 0.4396245777606964\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 941: Loss = 0.43279844522476196\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 942: Loss = 0.44026073813438416\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 943: Loss = 0.45808905363082886\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 944: Loss = 0.4587104618549347\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 945: Loss = 0.4629259407520294\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 946: Loss = 0.47731155157089233\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 947: Loss = 0.49891868233680725\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 948: Loss = 0.4896712005138397\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 949: Loss = 0.481434166431427\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 950: Loss = 0.47881650924682617\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 951: Loss = 0.4763103425502777\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 952: Loss = 0.48180991411209106\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 953: Loss = 0.4772859215736389\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 954: Loss = 0.4860970675945282\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 955: Loss = 0.4876547157764435\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 956: Loss = 0.48248085379600525\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 957: Loss = 0.485463410615921\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 958: Loss = 0.48115694522857666\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 959: Loss = 0.4748431146144867\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 960: Loss = 0.4614576995372772\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 961: Loss = 0.46669986844062805\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 962: Loss = 0.4587708115577698\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 963: Loss = 0.45754045248031616\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 964: Loss = 0.4674110412597656\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 965: Loss = 0.4631871283054352\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 966: Loss = 0.44960349798202515\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 967: Loss = 0.44858604669570923\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 968: Loss = 0.4575631320476532\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 969: Loss = 0.4484851360321045\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 970: Loss = 0.4410015642642975\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 971: Loss = 0.4351396858692169\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 972: Loss = 0.4274228513240814\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 973: Loss = 0.42910104990005493\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 974: Loss = 0.43552717566490173\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 975: Loss = 0.41346731781959534\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 976: Loss = 0.41574710607528687\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 977: Loss = 0.41427233815193176\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 978: Loss = 0.4109421968460083\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 979: Loss = 0.4105139970779419\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 980: Loss = 0.4089244604110718\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 981: Loss = 0.4051916301250458\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 982: Loss = 0.4050275385379791\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 983: Loss = 0.3988061547279358\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 984: Loss = 0.3827662467956543\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 985: Loss = 0.39698851108551025\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 986: Loss = 0.38653257489204407\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 987: Loss = 5.391594409942627\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 988: Loss = 0.37271204590797424\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 989: Loss = 0.3708847761154175\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 990: Loss = 0.3725627064704895\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 991: Loss = 0.38124388456344604\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 992: Loss = 0.36024710536003113\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 993: Loss = 0.36611637473106384\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 994: Loss = 0.3577325642108917\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 995: Loss = 0.9764530062675476\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 996: Loss = 0.3753543794155121\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 997: Loss = 0.40250837802886963\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 998: Loss = 0.4160468876361847\n",
      "\n",
      "Switching to Global Control!\n",
      "Episode 999: Loss = 0.4376286268234253\n",
      "\n",
      "Final Loss: 0.3577325642108917\n"
     ]
    }
   ],
   "source": [
    "# NOTE Old Training Loop\n",
    "gnn_out_chann = 4 # Num of features out\n",
    "rl_out_channels = 4 # Controlling valve positions (one output per node)\n",
    "hidden_channels = 128\n",
    "\n",
    "gnn = GCN(in_channels=gnn_in_chan, hidden_channels=hidden_channels, out_channels=gnn_out_chann).to(device)\n",
    "# NOTE input_dim should be 1 (gnn output) Controlling each node individually\n",
    "policy_network = PolicyNetwork(input_dim=gnn_out_chann, output_dim=rl_out_channels).to(device)\n",
    "optimizer = torch.optim.Adam(list(gnn.parameters()) + list(policy_network.parameters()), lr=1e-3)\n",
    "# scheduler = \n",
    "num_episodes = 1_000\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    node_representations = gnn(water_data)\n",
    "    graph_representation = torch.mean(node_representations, dim=0) # NOTE Basic for now\n",
    "    \n",
    "    current_water_levels = water_data.x[:, 0]\n",
    "    global_threshold = torch.quantile(current_water_levels, 0.9)\n",
    "    actions = hybrid_control(node_representations, policy_network, global_threshold, current_water_levels)\n",
    "    # Environment - simulates water dynamics after each action\n",
    "    new_state, reward = environment_step(node_representations, actions, water_data.edge_index, flow_capacities)\n",
    "    loss = -reward.mean()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if loss < best_loss: \n",
    "        best_loss = loss\n",
    "    \n",
    "    print(f'Episode {episode}: Loss = {loss.item()}\\n')\n",
    "print(f'Final Loss: {best_loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAT\n",
    "In the GAT layer, the node representations are updated using attention mechanisms:\n",
    "\n",
    "$$\n",
    "h_v' = \\sum_{u \\in \\mathcal{N}(v)} \\alpha_{vu} W h_u\n",
    "$$\n",
    "\n",
    "where $ \\alpha_{vu} $ is the attention coefficient between node $ v $ and node $ u $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
